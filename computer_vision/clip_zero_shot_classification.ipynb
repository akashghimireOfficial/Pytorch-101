{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import clip \n",
    "import torch \n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import OxfordIIITPet\n",
    "from torch.utils.data import DataLoader\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "clip_preprocess_tensor = transforms.Compose([\n",
    "    transforms.Resize(224),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.48145466, 0.4578275, 0.40821073],\n",
    "        std=[0.26862954, 0.26130258, 0.27577711]\n",
    "    )\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset=OxfordIIITPet(root='../data/',\n",
    "                            split='test',\n",
    "                            transform=clip_preprocess_tensor,\n",
    "                            download=False)\n",
    "cls_names=test_dataset.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (img,lbl) in test_dataset:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=8\n",
    "test_dataloader=DataLoader(dataset=test_dataset,\n",
    "                           batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for imgs,lbls in test_dataloader:\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Pretrained model for zero shot classification "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "device='cuda:1' if torch.cuda.is_available() else 'cpu'\n",
    "model,preprocess=clip.load('ViT-L/14',device=device)\n",
    "model=model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating text features by using different forms of prompts; \n",
    "\n",
    "see the list `prompt_templates` for reference\n",
    "\n",
    "And for the final text_features, we will take mean of all the prompt for each class \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "prompt_templates = [\n",
    "    '{}',\n",
    "    'a bad photo of a {}.',\n",
    "    'a photo of many {}.',\n",
    "    'a sculpture of a {}.',\n",
    "    'a photo of the hard to see {}.',\n",
    "    'a low resolution photo of the {}.',\n",
    "    'a rendering of a {}.',\n",
    "    'graffiti of a {}.',\n",
    "    'a bad photo of the {}.',\n",
    "    'a cropped photo of the {}.',\n",
    "    'a tattoo of a {}.',\n",
    "    'the embroidered {}.',\n",
    "    'a photo of a hard to see {}.',\n",
    "    'a bright photo of a {}.',\n",
    "    'a photo of a clean {}.',\n",
    "    'a photo of a dirty {}.',\n",
    "    'a dark photo of the {}.',\n",
    "    'a drawing of a {}.',\n",
    "    'a photo of my {}.',\n",
    "    'the plastic {}.',\n",
    "    'a photo of the cool {}.',\n",
    "    'a close-up photo of a {}.',\n",
    "    'a black and white photo of the {}.',\n",
    "    'a painting of the {}.',\n",
    "    'a painting of a {}.',\n",
    "    'a pixelated photo of the {}.',\n",
    "    'a sculpture of the {}.',\n",
    "    'a bright photo of the {}.',\n",
    "    'a cropped photo of a {}.',\n",
    "    'a plastic {}.',\n",
    "    'a photo of the dirty {}.',\n",
    "    'a jpeg corrupted photo of a {}.',\n",
    "    'a blurry photo of the {}.',\n",
    "    'a photo of the {}.',\n",
    "    'a good photo of the {}.',\n",
    "    'a rendering of the {}.',\n",
    "    'a {} in a video game.',\n",
    "    'a photo of one {}.',\n",
    "    'a doodle of a {}.',\n",
    "    'a close-up photo of the {}.',\n",
    "    'a photo of a {}.',\n",
    "    'the origami {}.',\n",
    "    'the {} in a video game.',\n",
    "    'a sketch of a {}.',\n",
    "    'a doodle of the {}.',\n",
    "    'a origami {}.',\n",
    "    'a low resolution photo of a {}.',\n",
    "    'the toy {}.',\n",
    "    'a rendition of the {}.',\n",
    "    'a photo of the clean {}.',\n",
    "    'a photo of a large {}.',\n",
    "    'a rendition of a {}.',\n",
    "    'a photo of a nice {}.',\n",
    "    'a photo of a weird {}.',\n",
    "    'a blurry photo of a {}.',\n",
    "    'a cartoon {}.',\n",
    "    'art of a {}.',\n",
    "    'a sketch of the {}.',\n",
    "    'a embroidered {}.',\n",
    "    'a pixelated photo of a {}.',\n",
    "    'itap of the {}.',\n",
    "    'a jpeg corrupted photo of the {}.',\n",
    "    'a good photo of a {}.',\n",
    "    'a plushie {}.',\n",
    "    'a photo of the nice {}.',\n",
    "    'a photo of the small {}.',\n",
    "    'a photo of the weird {}.',\n",
    "    'the cartoon {}.',\n",
    "    'art of the {}.',\n",
    "    'a drawing of the {}.',\n",
    "    'a photo of the large {}.',\n",
    "    'a black and white photo of a {}.',\n",
    "    'the plushie {}.',\n",
    "    'a dark photo of a {}.',\n",
    "    'itap of a {}.',\n",
    "    'graffiti of the {}.',\n",
    "    'a toy {}.',\n",
    "    'itap of my {}.',\n",
    "    'a photo of a cool {}.',\n",
    "    'a photo of a small {}.',\n",
    "    'a tattoo of the {}.',\n",
    "]\n",
    "# prompt_templates=['A photo of {}']\n",
    "\n",
    "def get_text_prompts(classes):\n",
    "    text_prompts=[]\n",
    "    for templete in prompt_templates:\n",
    "        templete_prompts=[]\n",
    "        for c in classes:\n",
    "            prompt=templete.replace('{}',c)\n",
    "            templete_prompts.append(prompt)\n",
    "        text_prompts.append(templete_prompts)\n",
    "\n",
    "    return text_prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_prompts=get_text_prompts(cls_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a bad photo of a Abyssinian.',\n",
       " 'a bad photo of a American Bulldog.',\n",
       " 'a bad photo of a American Pit Bull Terrier.',\n",
       " 'a bad photo of a Basset Hound.',\n",
       " 'a bad photo of a Beagle.',\n",
       " 'a bad photo of a Bengal.',\n",
       " 'a bad photo of a Birman.',\n",
       " 'a bad photo of a Bombay.',\n",
       " 'a bad photo of a Boxer.',\n",
       " 'a bad photo of a British Shorthair.',\n",
       " 'a bad photo of a Chihuahua.',\n",
       " 'a bad photo of a Egyptian Mau.',\n",
       " 'a bad photo of a English Cocker Spaniel.',\n",
       " 'a bad photo of a English Setter.',\n",
       " 'a bad photo of a German Shorthaired.',\n",
       " 'a bad photo of a Great Pyrenees.',\n",
       " 'a bad photo of a Havanese.',\n",
       " 'a bad photo of a Japanese Chin.',\n",
       " 'a bad photo of a Keeshond.',\n",
       " 'a bad photo of a Leonberger.',\n",
       " 'a bad photo of a Maine Coon.',\n",
       " 'a bad photo of a Miniature Pinscher.',\n",
       " 'a bad photo of a Newfoundland.',\n",
       " 'a bad photo of a Persian.',\n",
       " 'a bad photo of a Pomeranian.',\n",
       " 'a bad photo of a Pug.',\n",
       " 'a bad photo of a Ragdoll.',\n",
       " 'a bad photo of a Russian Blue.',\n",
       " 'a bad photo of a Saint Bernard.',\n",
       " 'a bad photo of a Samoyed.',\n",
       " 'a bad photo of a Scottish Terrier.',\n",
       " 'a bad photo of a Shiba Inu.',\n",
       " 'a bad photo of a Siamese.',\n",
       " 'a bad photo of a Sphynx.',\n",
       " 'a bad photo of a Staffordshire Bull Terrier.',\n",
       " 'a bad photo of a Wheaten Terrier.',\n",
       " 'a bad photo of a Yorkshire Terrier.']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_prompts[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_tokens=[]\n",
    "\n",
    "with torch.no_grad():\n",
    "    for text_prompt in text_prompts:\n",
    "        text_token=clip.tokenize(text_prompt).to(device)\n",
    "        text_tokens.append(text_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text_tokens[0].shape  torch.Size([37, 77])\n",
      "tensor([[49406, 16342,   690,  ...,     0,     0,     0],\n",
      "        [49406,  2151, 15611,  ...,     0,     0,     0],\n",
      "        [49406,  2151,  7476,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [49406, 29198,  6029,  ...,     0,     0,     0],\n",
      "        [49406, 20505,   576,  ...,     0,     0,     0],\n",
      "        [49406,  8633, 14455,  ...,     0,     0,     0]], device='cuda:1',\n",
      "       dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "print('text_tokens[0].shape ', text_tokens[0].shape)\n",
    "print(text_tokens[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_features=[]\n",
    "with torch.no_grad():\n",
    "    for token in text_tokens:\n",
    "        text_feature=model.encode_text(token)\n",
    "        text_features.append(text_feature)\n",
    "\n",
    "text_features=torch.mean(torch.stack(text_features),dim=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to do Zero-Shot Classification\n",
    "- First, we will extract image features for each image\n",
    "- Second, we will measure, how each image allign with the given labels; we will do this by calculating the ``similarity`` between image features and text features, and will take the argmax for predicting the final class label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Zero-Shot Classification in Progress: 100%|██████████| 459/459 [00:23<00:00, 19.72it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np \n",
    "batch_accuracy=[]\n",
    "\n",
    "for img,lbls in tqdm(test_dataloader,desc='Zero-Shot Classification in Progress'):\n",
    "    img_features=model.encode_image(img.to(device))\n",
    "    similarity=img_features @ text_features.T\n",
    "    pred_cls=torch.argmax(similarity,dim=1).cpu()\n",
    "    acc_bool=(pred_cls==lbls).to(dtype=torch.float32)\n",
    "    acc=(torch.sum(acc_bool)/len(pred_cls)).cpu().item()\n",
    "    batch_accuracy.append(acc)\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zero Shot Image Classification  91.285\n"
     ]
    }
   ],
   "source": [
    "accuracy=round(np.mean(batch_accuracy,axis=0)*100,3)\n",
    "print('Zero Shot Image Classification ', accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this jupyter notebook we witnessed the capacity of zero shot classification of `91.26%` in ``OxfordIIITPet`` containing `37` classes. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "akash",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
