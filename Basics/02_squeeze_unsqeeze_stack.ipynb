{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this turtorial we will learn some of the basics concepts of torch. Mainly: ``a) torch.unsqueeze(), b)torch.squeeze(), c) torch.stack(), d) torch.unbind()``"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ``torch.unsqueeze()``\n",
    "\n",
    "This is very similar to what we use \"np.expand_dims()\" or \"tf.expand_dims()\" in NumPy and Tensoforflow. \n",
    "\n",
    "**Parameters**\n",
    "\n",
    "- **input:Tensor**: the input tensor\n",
    "- **dim:int**: *default=0* set dim at 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original tensor shape: torch.Size([2, 3])\n",
      "Shape of tensor unsqueezed at dimension 0:torch.Size([1, 2, 3])\n",
      "Shape of tensor unsqueezed at dimension 1:torch.Size([2, 1, 3])\n",
      "Shape of tensor unsqueezed at dimension 2:torch.Size([2, 3, 1])\n"
     ]
    }
   ],
   "source": [
    "### creating a random_tensor\n",
    "\n",
    "tensor_example=torch.rand(size=(2,3)) ## will have a shape of 0\n",
    "\n",
    "tensor_example_exp_dim0=torch.unsqueeze(tensor_example,axis=0)\n",
    "tensor_example_exp_dim1=torch.unsqueeze(tensor_example,dim=1)\n",
    "tensor_example_exp_dim2=torch.unsqueeze(tensor_example,dim=2)\n",
    "\n",
    "print(f'Original tensor shape: {tensor_example.shape}')\n",
    "print(f'Shape of tensor unsqueezed at dimension 0:{tensor_example_exp_dim0.shape}')\n",
    "print(f'Shape of tensor unsqueezed at dimension 1:{tensor_example_exp_dim1.shape}')\n",
    "print(f'Shape of tensor unsqueezed at dimension 2:{tensor_example_exp_dim2.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alternative for torch.unsqueeze()\n",
    "\n",
    "We can simply achieve the same above thing by using \"tensor[None,...]\" this will expand in dim=0; more example below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original tensor shape: torch.Size([2, 3])\n",
      "Shape of tensor unsqueezed at dimension 0:torch.Size([1, 2, 3])\n",
      "Shape of tensor unsqueezed at dimension 1:torch.Size([2, 3, 1])\n"
     ]
    }
   ],
   "source": [
    "tensor_example=torch.rand(size=(2,3)) ## will have a shape of 0\n",
    "\n",
    "tensor_example_exp_dim0=tensor_example[None,...]\n",
    "tensor_example_exp_dim1=tensor_example[...,None,...]\n",
    "\n",
    "\n",
    "print(f'Original tensor shape: {tensor_example.shape}')\n",
    "print(f'Shape of tensor unsqueezed at dimension 0:{tensor_example_exp_dim0.shape}')\n",
    "print(f'Shape of tensor unsqueezed at dimension 1:{tensor_example_exp_dim1.shape}')\n",
    "# print(f'Shape of tensor unsqueezed at dimension 2:{tensor_example_exp_dim2.shape}') this is better to use with above method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ``torch.squeeze()``\n",
    "\n",
    "This is similar to reduce_dims(). Note, we can only reduce the dims of tensor which have shape value of 1. That is we can added extra added dims\n",
    "\n",
    "***Parameters***\n",
    "**input:tensor**: input_tensor\n",
    "**dim:int, optional**: if not given by default will squeeze all the extra added dims; if provided will squeeze only that dims."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original tensor_example shape: torch.Size([1, 2, 1, 3, 1])\n",
      "Squeeze all dims: torch.Size([2, 3])\n",
      "Squeeze dims0: torch.Size([2, 1, 3, 1])\n",
      "Squeeze dims2: torch.Size([1, 2, 3, 1])\n",
      "Squeeze dims last: torch.Size([1, 2, 1, 3])\n"
     ]
    }
   ],
   "source": [
    "tensor_example=torch.rand(size=(1,2,1,3,1)) ## will have a shape of 0\n",
    "squeezed_tensor=tensor_example.squeeze()\n",
    "squeezed_tensor_dim0=tensor_example.squeeze(dim=0)\n",
    "squeezed_tensor_dim2=tensor_example.squeeze(dim=2)\n",
    "squeezed_tensor_dim_last=tensor_example.squeeze(dim=-1)\n",
    "\n",
    "print(f'original tensor_example shape: {tensor_example.shape}')\n",
    "print(f'Squeeze all dims: {squeezed_tensor.shape}')\n",
    "print(f'Squeeze dims0: {squeezed_tensor_dim0.shape}')\n",
    "print(f'Squeeze dims2: {squeezed_tensor_dim2.shape}')\n",
    "print(f'Squeeze dims last: {squeezed_tensor_dim_last.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `torch.stack()`\n",
    "\n",
    "`torch.stack(tensors, dim=0)`\n",
    "\n",
    "- **Parameters:**\n",
    "  - `tensors` (sequence of Tensors): A sequence of tensors to be stacked.\n",
    "  - `dim` (int, optional): The dimension along which the tensors will be stacked. Default is `0`.\n",
    "\n",
    "- **Returns:**\n",
    "  - A new tensor formed by stacking the input tensors along the specified dimension `dim`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of the stacked tensors dim 0: torch.Size([2, 2, 3, 5])\n",
      "shape of the stacked tensors dim 1: torch.Size([2, 2, 3, 5])\n",
      "shape of the stacked tensors dim 2: torch.Size([2, 3, 2, 5])\n"
     ]
    }
   ],
   "source": [
    "## example use of tensor\n",
    "tensor_1=torch.rand(2,3,5)\n",
    "tensor_2=torch.rand(2,3,5)\n",
    "\n",
    "stacked_dim0=torch.stack([tensor_1,tensor_2],axis=0)\n",
    "stacked_dim1=torch.stack([tensor_1,tensor_2],axis=1)\n",
    "stacked_dim2=torch.stack([tensor_1,tensor_2],axis=2)\n",
    "print(f'shape of the stacked tensors dim 0: {stacked_dim0.shape}')\n",
    "print(f'shape of the stacked tensors dim 1: {stacked_dim1.shape}')\n",
    "print(f'shape of the stacked tensors dim 2: {stacked_dim2.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `torch.unbind()`\n",
    "\n",
    "`torch.unbind(input, dim=0)`\n",
    "\n",
    "> Equivalent of tf.unstack()\n",
    "\n",
    "- **Parameters:**\n",
    "  - `input` (Tensor): The input tensor to be unbound.\n",
    "  - `dim` (int, optional): The dimension along which the tensor will be unbound. Default is `0`.\n",
    "\n",
    "- **Returns:**\n",
    "  - A tuple of tensors containing the slices of the input tensor along the specified dimension `dim`.\n",
    "\n",
    "- **Description:**\n",
    "  - `torch.unbind()` splits a tensor into a tuple of tensors along a specified dimension `dim`.\n",
    "  - The input tensor `input` is split into slices along the dimension `dim`, and each slice becomes an element of the output tuple.\n",
    "  - The dimension `dim` is removed from the shape of the output tensors.\n",
    "  - If `dim` is not specified, it defaults to `0`, which means the tensor is split along the first dimension.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor_1.shape: torch.Size([2, 3, 5]) | tensor_2.shape: torch.Size([2, 3, 5])\n",
      "tensor_1.shape: torch.Size([2, 3, 5]) | tensor_2.shape: torch.Size([2, 3, 5])\n"
     ]
    }
   ],
   "source": [
    "tensor_1,tensor_2=torch.unbind(stacked_dim0,dim=0)\n",
    "print(f'tensor_1.shape: {tensor_1.shape} | tensor_2.shape: {tensor_2.shape}')\n",
    "tensor_1,tensor_2=torch.unbind(stacked_dim1,dim=1)\n",
    "print(f'tensor_1.shape: {tensor_1.shape} | tensor_2.shape: {tensor_2.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 5])\n",
      "torch.Size([2, 5])\n",
      "torch.Size([2, 5])\n"
     ]
    }
   ],
   "source": [
    "tensor_a,tensor_b,tensor_c=torch.unbind((torch.rand(size=(3,2,5))),dim=0)\n",
    "print(tensor_a.shape)\n",
    "print(tensor_b.shape)\n",
    "print(tensor_c.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 5])\n",
      "torch.Size([3, 5])\n"
     ]
    }
   ],
   "source": [
    "tensor_a,tensor_b=torch.unbind((torch.rand(size=(3,2,5))),dim=1)\n",
    "print(tensor_a.shape)\n",
    "print(tensor_b.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 2])\n",
      "torch.Size([3, 2])\n",
      "torch.Size([2, 5])\n",
      "torch.Size([3, 2])\n",
      "torch.Size([3, 2])\n"
     ]
    }
   ],
   "source": [
    "tensor_a,tensor_b,torch_c,tensor_d,tensor_e=torch.unbind((torch.rand(size=(3,2,5))),dim=2)\n",
    "print(tensor_a.shape)\n",
    "print(tensor_b.shape)\n",
    "print(tensor_c.shape)\n",
    "print(tensor_d.shape)\n",
    "print(tensor_e.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ``torch.cat()`` \n",
    "\n",
    "concatenate tensors to single tensor; \n",
    "\n",
    "**Parameters**: ``torch.cat(tensors,dim=0)``\n",
    "\n",
    "- tensors: Sequences of tensors\n",
    "- dim: dim in which tensor to be concatenated; if dim=0; the rest dimension must be same and vide versa; \n",
    "\n",
    "**returns**: returns a single concatenated tensors \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_a=torch.rand(size=(2,3))\n",
    "tensor_b=torch.rand(size=(1,3))\n",
    "\n",
    "cat_ab_0=torch.cat(tensors=(tensor_a,tensor_b),dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8304, 0.6848, 0.5624],\n",
       "        [0.3313, 0.6885, 0.7969],\n",
       "        [0.9210, 0.3923, 0.5522]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_ab_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 3])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_ab_0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "##cat in dim =1\n",
    "tensor_a=torch.rand(size=(2,3))\n",
    "tensor_b=torch.rand(size=(2,1))\n",
    "\n",
    "cat_ab_1=torch.cat(tensors=(tensor_a,tensor_b),dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_ab_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9930, 0.3555, 0.9500, 0.6431],\n",
       "        [0.3203, 0.6716, 0.9522, 0.0692]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_ab_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vision",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
