{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn \n",
    "from torch.optim import SGD\n",
    "\n",
    "from torch.utils.data import Dataset,DataLoader,random_split\n",
    "from torch.nn.functional import one_hot\n",
    "\n",
    "## Other modules \n",
    "\n",
    "import numpy as np \n",
    "\n",
    "import os \n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "## defining a custom dataset \n",
    "\n",
    "class WineDataset(Dataset):\n",
    "\n",
    "    def __init__(self,transform=None):\n",
    "\n",
    "        super(WineDataset,self).__init__()\n",
    "        xy = np.loadtxt('./data/wine/wine.csv', delimiter=',', dtype=np.float32, skiprows=1)\n",
    "        X,y=xy[:,1:],xy[:,0]# y will be reshape .reshape(-1,1) when use bracket\n",
    "        self.num_class=np.unique(y).shape[0]\n",
    "        self.num_samples=xy.shape[0]\n",
    "        self.x_data=torch.from_numpy(X)\n",
    "        self.y_data=torch.from_numpy(y).to(torch.int64)-1 ## dont accept int32 for some reasons \n",
    "\n",
    "        print('Num of Class: {}'.format(self.num_class))\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_samples\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        x=self.x_data[index]\n",
    "        #y=one_hot(self.y_data[index],self.num_class); In pytorch nn.CrossEntropyLoss automatically handles raw dataset without hot-encodding\n",
    "        return x,self.y_data[index]\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of Class: 3\n",
      "torch.Size([3, 13])\n",
      "torch.Size([3])\n"
     ]
    }
   ],
   "source": [
    "dataset=WineDataset()\n",
    "x,y=dataset[:3]\n",
    "print(x.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(101)\n",
    "\n",
    "total_size=len(dataset)\n",
    "train_size=int(0.7*total_size)\n",
    "val_size=int(0.15*total_size)\n",
    "test_size=total_size-train_size-val_size\n",
    "\n",
    "train_dataset,val_dataset,test_dataset=random_split(dataset=dataset,lengths=[train_size,val_size,test_size]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader=DataLoader(dataset=train_dataset,\n",
    "                            batch_size=32,\n",
    "                            shuffle=True,\n",
    "                            num_workers=2)\n",
    "\n",
    "val_dataloader=DataLoader(dataset=val_dataset,\n",
    "                            batch_size=32,\n",
    "                            shuffle=True,\n",
    "                            num_workers=2)\n",
    "\n",
    "test_dataloader=DataLoader(dataset=test_dataset,\n",
    "                            batch_size=32,\n",
    "                            shuffle=True,\n",
    "                            num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 13])\n",
      "torch.Size([32])\n"
     ]
    }
   ],
   "source": [
    "## The above dataloader is in the iterator form. \n",
    "\n",
    "dataiter=iter(train_dataloader)\n",
    "feat,lbs=next(dataiter)\n",
    "print(feat.shape) ## batch_size,\n",
    "print(lbs.shape) ## batch_size,num_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features=13\n",
    "num_class=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WineClassModel(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(WineClassModel,self).__init__()\n",
    "        self.nn=nn.Sequential(nn.Linear(13,256),\n",
    "                              nn.ReLU(),\n",
    "                              nn.Dropout(0.5),\n",
    "                              nn.Linear(256,128),\n",
    "                              nn.ReLU(),\n",
    "                              nn.Dropout(0.5),\n",
    "                              nn.Linear(128,3)\n",
    "        )\n",
    "        \n",
    "    def forward(self,x):\n",
    "        return self.nn(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=WineClassModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs=100\n",
    "criterion=nn.CrossEntropyLoss()\n",
    "opt=SGD(model.parameters(),lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking the model\n",
    "\n",
    "model(x).shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=torch.tensor([1,2,3,4])\n",
    "b=torch.tensor([1,2,5,7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_306335/896790710.py:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(a==b,dtype=torch.float16).sum().item()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2.0"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(a==b,dtype=torch.float16).sum().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0/100 | Step: 0/32\n",
      "loss: 1.159\n",
      "Epoch: 1/100 | Step: 0/32\n",
      "loss: 1.073\n",
      "Epoch: 2/100 | Step: 0/32\n",
      "loss: 1.027\n",
      "Epoch: 3/100 | Step: 0/32\n",
      "loss: 1.081\n",
      "Epoch: 4/100 | Step: 0/32\n",
      "loss: 1.095\n",
      "Epoch: 5/100 | Step: 0/32\n",
      "loss: 1.078\n",
      "Epoch: 6/100 | Step: 0/32\n",
      "loss: 1.073\n",
      "Epoch: 7/100 | Step: 0/32\n",
      "loss: 1.087\n",
      "Epoch: 8/100 | Step: 0/32\n",
      "loss: 1.223\n",
      "Epoch: 9/100 | Step: 0/32\n",
      "loss: 1.102\n",
      "Epoch: 10/100 | Step: 0/32\n",
      "loss: 1.163\n",
      "Epoch: 11/100 | Step: 0/32\n",
      "loss: 1.107\n",
      "Epoch: 12/100 | Step: 0/32\n",
      "loss: 1.020\n",
      "Epoch: 13/100 | Step: 0/32\n",
      "loss: 1.096\n",
      "Epoch: 14/100 | Step: 0/32\n",
      "loss: 1.063\n",
      "Epoch: 15/100 | Step: 0/32\n",
      "loss: 1.086\n",
      "Epoch: 16/100 | Step: 0/32\n",
      "loss: 1.113\n",
      "Epoch: 17/100 | Step: 0/32\n",
      "loss: 0.994\n",
      "Epoch: 18/100 | Step: 0/32\n",
      "loss: 1.195\n",
      "Epoch: 19/100 | Step: 0/32\n",
      "loss: 1.024\n",
      "Epoch: 20/100 | Step: 0/32\n",
      "loss: 1.115\n",
      "Epoch: 21/100 | Step: 0/32\n",
      "loss: 1.057\n",
      "Epoch: 22/100 | Step: 0/32\n",
      "loss: 1.074\n",
      "Epoch: 23/100 | Step: 0/32\n",
      "loss: 1.046\n",
      "Epoch: 24/100 | Step: 0/32\n",
      "loss: 1.120\n",
      "Epoch: 25/100 | Step: 0/32\n",
      "loss: 1.188\n",
      "Epoch: 26/100 | Step: 0/32\n",
      "loss: 1.153\n",
      "Epoch: 27/100 | Step: 0/32\n",
      "loss: 1.066\n",
      "Epoch: 28/100 | Step: 0/32\n",
      "loss: 1.034\n",
      "Epoch: 29/100 | Step: 0/32\n",
      "loss: 1.079\n",
      "Epoch: 30/100 | Step: 0/32\n",
      "loss: 1.089\n",
      "Epoch: 31/100 | Step: 0/32\n",
      "loss: 1.114\n",
      "Epoch: 32/100 | Step: 0/32\n",
      "loss: 0.976\n",
      "Epoch: 33/100 | Step: 0/32\n",
      "loss: 1.131\n",
      "Epoch: 34/100 | Step: 0/32\n",
      "loss: 1.099\n",
      "Epoch: 35/100 | Step: 0/32\n",
      "loss: 1.206\n",
      "Epoch: 36/100 | Step: 0/32\n",
      "loss: 1.040\n",
      "Epoch: 37/100 | Step: 0/32\n",
      "loss: 1.081\n",
      "Epoch: 38/100 | Step: 0/32\n",
      "loss: 1.148\n",
      "Epoch: 39/100 | Step: 0/32\n",
      "loss: 1.149\n",
      "Epoch: 40/100 | Step: 0/32\n",
      "loss: 1.086\n",
      "Epoch: 41/100 | Step: 0/32\n",
      "loss: 1.006\n",
      "Epoch: 42/100 | Step: 0/32\n",
      "loss: 1.132\n",
      "Epoch: 43/100 | Step: 0/32\n",
      "loss: 1.157\n",
      "Epoch: 44/100 | Step: 0/32\n",
      "loss: 1.126\n",
      "Epoch: 45/100 | Step: 0/32\n",
      "loss: 0.975\n",
      "Epoch: 46/100 | Step: 0/32\n",
      "loss: 1.063\n",
      "Epoch: 47/100 | Step: 0/32\n",
      "loss: 1.046\n",
      "Epoch: 48/100 | Step: 0/32\n",
      "loss: 1.103\n",
      "Epoch: 49/100 | Step: 0/32\n",
      "loss: 1.088\n",
      "Epoch: 50/100 | Step: 0/32\n",
      "loss: 1.135\n",
      "Epoch: 51/100 | Step: 0/32\n",
      "loss: 1.181\n",
      "Epoch: 52/100 | Step: 0/32\n",
      "loss: 1.149\n",
      "Epoch: 53/100 | Step: 0/32\n",
      "loss: 1.067\n",
      "Epoch: 54/100 | Step: 0/32\n",
      "loss: 1.078\n",
      "Epoch: 55/100 | Step: 0/32\n",
      "loss: 1.194\n",
      "Epoch: 56/100 | Step: 0/32\n",
      "loss: 1.051\n",
      "Epoch: 57/100 | Step: 0/32\n",
      "loss: 1.068\n",
      "Epoch: 58/100 | Step: 0/32\n",
      "loss: 1.070\n",
      "Epoch: 59/100 | Step: 0/32\n",
      "loss: 1.050\n",
      "Epoch: 60/100 | Step: 0/32\n",
      "loss: 1.152\n",
      "Epoch: 61/100 | Step: 0/32\n",
      "loss: 1.165\n",
      "Epoch: 62/100 | Step: 0/32\n",
      "loss: 1.149\n",
      "Epoch: 63/100 | Step: 0/32\n",
      "loss: 1.010\n",
      "Epoch: 64/100 | Step: 0/32\n",
      "loss: 1.097\n",
      "Epoch: 65/100 | Step: 0/32\n",
      "loss: 1.140\n",
      "Epoch: 66/100 | Step: 0/32\n",
      "loss: 1.057\n",
      "Epoch: 67/100 | Step: 0/32\n",
      "loss: 1.036\n",
      "Epoch: 68/100 | Step: 0/32\n",
      "loss: 1.016\n",
      "Epoch: 69/100 | Step: 0/32\n",
      "loss: 1.079\n",
      "Epoch: 70/100 | Step: 0/32\n",
      "loss: 1.071\n",
      "Epoch: 71/100 | Step: 0/32\n",
      "loss: 1.096\n",
      "Epoch: 72/100 | Step: 0/32\n",
      "loss: 1.106\n",
      "Epoch: 73/100 | Step: 0/32\n",
      "loss: 1.081\n",
      "Epoch: 74/100 | Step: 0/32\n",
      "loss: 1.159\n",
      "Epoch: 75/100 | Step: 0/32\n",
      "loss: 1.091\n",
      "Epoch: 76/100 | Step: 0/32\n",
      "loss: 1.081\n",
      "Epoch: 77/100 | Step: 0/32\n",
      "loss: 1.158\n",
      "Epoch: 78/100 | Step: 0/32\n",
      "loss: 1.138\n",
      "Epoch: 79/100 | Step: 0/32\n",
      "loss: 1.136\n",
      "Epoch: 80/100 | Step: 0/32\n",
      "loss: 1.059\n",
      "Epoch: 81/100 | Step: 0/32\n",
      "loss: 1.044\n",
      "Epoch: 82/100 | Step: 0/32\n",
      "loss: 1.116\n",
      "Epoch: 83/100 | Step: 0/32\n",
      "loss: 1.214\n",
      "Epoch: 84/100 | Step: 0/32\n",
      "loss: 1.133\n",
      "Epoch: 85/100 | Step: 0/32\n",
      "loss: 1.034\n",
      "Epoch: 86/100 | Step: 0/32\n",
      "loss: 1.053\n",
      "Epoch: 87/100 | Step: 0/32\n",
      "loss: 1.054\n",
      "Epoch: 88/100 | Step: 0/32\n",
      "loss: 1.034\n",
      "Epoch: 89/100 | Step: 0/32\n",
      "loss: 1.205\n",
      "Epoch: 90/100 | Step: 0/32\n",
      "loss: 1.115\n",
      "Epoch: 91/100 | Step: 0/32\n",
      "loss: 1.075\n",
      "Epoch: 92/100 | Step: 0/32\n",
      "loss: 1.019\n",
      "Epoch: 93/100 | Step: 0/32\n",
      "loss: 1.124\n",
      "Epoch: 94/100 | Step: 0/32\n",
      "loss: 1.042\n",
      "Epoch: 95/100 | Step: 0/32\n",
      "loss: 1.219\n",
      "Epoch: 96/100 | Step: 0/32\n",
      "loss: 1.085\n",
      "Epoch: 97/100 | Step: 0/32\n",
      "loss: 1.088\n",
      "Epoch: 98/100 | Step: 0/32\n",
      "loss: 1.074\n",
      "Epoch: 99/100 | Step: 0/32\n",
      "loss: 1.065\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "\n",
    "    for step_num,(features,labels) in enumerate(train_dataloader):\n",
    "        pred_labels=model(features)\n",
    "        loss=criterion(pred_labels,labels)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "\n",
    "        if step_num%32==0:\n",
    "\n",
    "            print('Epoch: {}/{} | Step: {}/{}'.format(epoch,num_epochs,step_num,32))\n",
    "            print('loss: {:.3f}'.format(loss.item()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WineClassModel(\n",
       "  (nn): Sequential(\n",
       "    (0): Linear(in_features=13, out_features=256, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): Linear(in_features=256, out_features=128, bias=True)\n",
       "    (4): ReLU()\n",
       "    (5): Dropout(p=0.5, inplace=False)\n",
       "    (6): Linear(in_features=128, out_features=3, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Now for evaluation set to model.eval()\n",
    "\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.3571428656578064]\n",
      "Average Accuracy: 0.36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_306335/3893402697.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  true_prediction=torch.tensor(pred_labels==test_labels,dtype=torch.float32).sum()\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    accuracies=[]\n",
    "\n",
    "    for test_features,test_labels in test_dataloader:\n",
    "        pred_labels=model(test_features)\n",
    "        pred_labels=torch.argmax(pred_labels,1)\n",
    "        true_prediction=torch.tensor(pred_labels==test_labels,dtype=torch.float32).sum()\n",
    "        total_batch_size=torch.tensor(pred_labels.shape[0],dtype=torch.float32)\n",
    "        accuracies.append(torch.div(true_prediction,total_batch_size).item())\n",
    "        print(accuracies)\n",
    "\n",
    "\n",
    "print('Average Accuracy: {:.2f}'.format(np.mean(accuracies)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5.)"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.div(10,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2.799999952316284]"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vision",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
