{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "from torch.optim import SGD,lr_scheduler\n",
    "from torch.nn import Sequential, Linear, Embedding\n",
    "from torch.utils.data import DataLoader\n",
    "import torchtext\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##other library\n",
    "import numpy as np\n",
    "import datasets\n",
    "import os \n",
    "import tqdm\n",
    "import collections\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device:  cuda\n"
     ]
    }
   ],
   "source": [
    "device=('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('device: ',device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed=1234\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic=True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data,test_data=datasets.load_dataset('imdb',split=['train','test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label'],\n",
       "    num_rows: 25000\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I rented I AM CURIOUS-YELLOW from my video store because of all the controversy that surrounded it when it was first released in 1967. I also heard that at first it was seized by U.S. customs if it ever tried to enter this country, therefore being a fan of films considered \"controversial\" I really had to see this for myself.<br /><br />The plot is centered around a young Swedish drama student named Lena who wants to learn everything she can about life. In particular she wants to focus her attentions to making some sort of documentary on what the average Swede thought about certain political issues such as the Vietnam War and race issues in the United States. In between asking politicians and ordinary denizens of Stockholm about their opinions on politics, she has sex with her drama teacher, classmates, and married men.<br /><br />What kills me about I AM CURIOUS-YELLOW is that 40 years ago, this was considered pornographic. Really, the sex and nudity scenes are few and far between, even then it\\'s not shot like some cheaply made porno. While my countrymen mind find it shocking, in reality sex and nudity are a major staple in Swedish cinema. Even Ingmar Bergman, arguably their answer to good old boy John Ford, had sex scenes in his films.<br /><br />I do commend the filmmakers for the fact that any sex shown in the film is shown for artistic purposes rather than just to shock people and make money to be shown in pornographic theaters in America. I AM CURIOUS-YELLOW is a good film for anyone wanting to study the meat and potatoes (no pun intended) of Swedish cinema. But really, this film doesn\\'t have much of a plot.'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['text'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': Value(dtype='string', id=None),\n",
       " 'label': ClassLabel(names=['neg', 'pos'], id=None)}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.features ## have two labels neg and pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I rented I AM CURIOUS-YELLOW from my video store because of all the controversy that surrounded it w\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(train_data[0]['text'][:100])\n",
    "print(train_data[0]['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['text', 'label'])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0].keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenization\n",
    "\n",
    "ML models trains on numerical value only. So we will convert each string to int value using tokenizer. In order to do so first we need to separate `str` to individual tokens, and laters converts them into number. \n",
    "\n",
    "- using,`tokenizer` we will convert strings into number of tokens first. \n",
    "- later, we will use look_up_table  to convert each tokens(in str) to int. We do this by creating a vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer=torchtext.data.utils.get_tokenizer('basic_english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_text='Hello, I am from Nepal!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hello', ',', 'i', 'am', 'from', 'nepal', '!']\n"
     ]
    }
   ],
   "source": [
    "sample_tokenized_text=tokenizer(sample_text)\n",
    "print(sample_tokenized_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "## sometimes the str might contain to many unnecessary tokens; so we will take max_length and define by function\n",
    "\n",
    "def tokenize_example(example,tokenizer,max_length):\n",
    "    tokens=tokenizer(example['text'])[:max_length]\n",
    "    return {'tokens':tokens}\n",
    "\n",
    "## we return dictionary coz train_data are in the same format.  When use with map fucntion later we will see new tokens (with key) is appended in train_data format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I rented I AM CURIOUS-YELLOW from my video store because of all the controversy that surrounded it w'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0]['text'][:100] ##we will convert this to tokens using the above fucntion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_dict_sample=tokenize_example(train_data[0],tokenizer,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(token_dict_sample['tokens'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length=256\n",
    "\n",
    "train_data=train_data.map(tokenize_example,\n",
    "                          fn_kwargs={'tokenizer':tokenizer,\n",
    "                                     'max_length':max_length})\n",
    "\n",
    "test_data=test_data.map(tokenize_example,\n",
    "                          fn_kwargs={'tokenizer':tokenizer,\n",
    "                                     'max_length':max_length})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': Value(dtype='string', id=None),\n",
       " 'label': ClassLabel(names=['neg', 'pos'], id=None),\n",
       " 'tokens': Sequence(feature=Value(dtype='string', id=None), length=-1, id=None)}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label', 'tokens'],\n",
       "    num_rows: 25000\n",
       "})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "256"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data[0]['tokens']) ### mapped from above function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25000"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data['tokens']) ## will load will athe tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'rented',\n",
       " 'i',\n",
       " 'am',\n",
       " 'curious-yellow',\n",
       " 'from',\n",
       " 'my',\n",
       " 'video',\n",
       " 'store',\n",
       " 'because',\n",
       " 'of',\n",
       " 'all',\n",
       " 'the',\n",
       " 'controversy',\n",
       " 'that',\n",
       " 'surrounded',\n",
       " 'it',\n",
       " 'when',\n",
       " 'it',\n",
       " 'was',\n",
       " 'first',\n",
       " 'released',\n",
       " 'in',\n",
       " '1967',\n",
       " '.',\n",
       " 'i',\n",
       " 'also',\n",
       " 'heard',\n",
       " 'that',\n",
       " 'at',\n",
       " 'first',\n",
       " 'it',\n",
       " 'was',\n",
       " 'seized',\n",
       " 'by',\n",
       " 'u',\n",
       " '.',\n",
       " 's',\n",
       " '.',\n",
       " 'customs',\n",
       " 'if',\n",
       " 'it',\n",
       " 'ever',\n",
       " 'tried',\n",
       " 'to',\n",
       " 'enter',\n",
       " 'this',\n",
       " 'country',\n",
       " ',',\n",
       " 'therefore',\n",
       " 'being',\n",
       " 'a',\n",
       " 'fan',\n",
       " 'of',\n",
       " 'films',\n",
       " 'considered',\n",
       " 'controversial',\n",
       " 'i',\n",
       " 'really',\n",
       " 'had',\n",
       " 'to',\n",
       " 'see',\n",
       " 'this',\n",
       " 'for',\n",
       " 'myself',\n",
       " '.',\n",
       " 'the',\n",
       " 'plot',\n",
       " 'is',\n",
       " 'centered',\n",
       " 'around',\n",
       " 'a',\n",
       " 'young',\n",
       " 'swedish',\n",
       " 'drama',\n",
       " 'student',\n",
       " 'named',\n",
       " 'lena',\n",
       " 'who',\n",
       " 'wants',\n",
       " 'to',\n",
       " 'learn',\n",
       " 'everything',\n",
       " 'she',\n",
       " 'can',\n",
       " 'about',\n",
       " 'life',\n",
       " '.',\n",
       " 'in',\n",
       " 'particular',\n",
       " 'she',\n",
       " 'wants',\n",
       " 'to',\n",
       " 'focus',\n",
       " 'her',\n",
       " 'attentions',\n",
       " 'to',\n",
       " 'making',\n",
       " 'some',\n",
       " 'sort',\n",
       " 'of',\n",
       " 'documentary',\n",
       " 'on',\n",
       " 'what',\n",
       " 'the',\n",
       " 'average',\n",
       " 'swede',\n",
       " 'thought',\n",
       " 'about',\n",
       " 'certain',\n",
       " 'political',\n",
       " 'issues',\n",
       " 'such',\n",
       " 'as',\n",
       " 'the',\n",
       " 'vietnam',\n",
       " 'war',\n",
       " 'and',\n",
       " 'race',\n",
       " 'issues',\n",
       " 'in',\n",
       " 'the',\n",
       " 'united',\n",
       " 'states',\n",
       " '.',\n",
       " 'in',\n",
       " 'between',\n",
       " 'asking',\n",
       " 'politicians',\n",
       " 'and',\n",
       " 'ordinary',\n",
       " 'denizens',\n",
       " 'of',\n",
       " 'stockholm',\n",
       " 'about',\n",
       " 'their',\n",
       " 'opinions',\n",
       " 'on',\n",
       " 'politics',\n",
       " ',',\n",
       " 'she',\n",
       " 'has',\n",
       " 'sex',\n",
       " 'with',\n",
       " 'her',\n",
       " 'drama',\n",
       " 'teacher',\n",
       " ',',\n",
       " 'classmates',\n",
       " ',',\n",
       " 'and',\n",
       " 'married',\n",
       " 'men',\n",
       " '.',\n",
       " 'what',\n",
       " 'kills',\n",
       " 'me',\n",
       " 'about',\n",
       " 'i',\n",
       " 'am',\n",
       " 'curious-yellow',\n",
       " 'is',\n",
       " 'that',\n",
       " '40',\n",
       " 'years',\n",
       " 'ago',\n",
       " ',',\n",
       " 'this',\n",
       " 'was',\n",
       " 'considered',\n",
       " 'pornographic',\n",
       " '.',\n",
       " 'really',\n",
       " ',',\n",
       " 'the',\n",
       " 'sex',\n",
       " 'and',\n",
       " 'nudity',\n",
       " 'scenes',\n",
       " 'are',\n",
       " 'few',\n",
       " 'and',\n",
       " 'far',\n",
       " 'between',\n",
       " ',',\n",
       " 'even',\n",
       " 'then',\n",
       " 'it',\n",
       " \"'\",\n",
       " 's',\n",
       " 'not',\n",
       " 'shot',\n",
       " 'like',\n",
       " 'some',\n",
       " 'cheaply',\n",
       " 'made',\n",
       " 'porno',\n",
       " '.',\n",
       " 'while',\n",
       " 'my',\n",
       " 'countrymen',\n",
       " 'mind',\n",
       " 'find',\n",
       " 'it',\n",
       " 'shocking',\n",
       " ',',\n",
       " 'in',\n",
       " 'reality',\n",
       " 'sex',\n",
       " 'and',\n",
       " 'nudity',\n",
       " 'are',\n",
       " 'a',\n",
       " 'major',\n",
       " 'staple',\n",
       " 'in',\n",
       " 'swedish',\n",
       " 'cinema',\n",
       " '.',\n",
       " 'even',\n",
       " 'ingmar',\n",
       " 'bergman',\n",
       " ',',\n",
       " 'arguably',\n",
       " 'their',\n",
       " 'answer',\n",
       " 'to',\n",
       " 'good',\n",
       " 'old',\n",
       " 'boy',\n",
       " 'john',\n",
       " 'ford',\n",
       " ',',\n",
       " 'had',\n",
       " 'sex',\n",
       " 'scenes',\n",
       " 'in',\n",
       " 'his',\n",
       " 'films',\n",
       " '.',\n",
       " 'i',\n",
       " 'do',\n",
       " 'commend',\n",
       " 'the',\n",
       " 'filmmakers',\n",
       " 'for',\n",
       " 'the',\n",
       " 'fact',\n",
       " 'that',\n",
       " 'any',\n",
       " 'sex',\n",
       " 'shown',\n",
       " 'in',\n",
       " 'the',\n",
       " 'film',\n",
       " 'is']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['tokens'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0]['tokens']==train_data['tokens'][0]\n",
    "## however, train_data['tokens'][0] will load all dataset, and select first index. So, prefer to use train_data[0]['tokens'] to be used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'rented',\n",
       " 'i',\n",
       " 'am',\n",
       " 'curious-yellow',\n",
       " 'from',\n",
       " 'my',\n",
       " 'video',\n",
       " 'store',\n",
       " 'because',\n",
       " 'of',\n",
       " 'all',\n",
       " 'the',\n",
       " 'controversy',\n",
       " 'that',\n",
       " 'surrounded',\n",
       " 'it',\n",
       " 'when',\n",
       " 'it',\n",
       " 'was',\n",
       " 'first',\n",
       " 'released',\n",
       " 'in',\n",
       " '1967',\n",
       " '.']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0]['tokens'][:25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "## now we will split 25% of train_data to val_data\n",
    "\n",
    "train_valid_data=train_data.train_test_split(test_size=0.25)\n",
    "train_data=train_valid_data['train']\n",
    "val_data=train_valid_data['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18750"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data) ## total data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a vocabulary\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_freq=1\n",
    "special_tokens=['unk','pad'] ## vocabs which appears less than 5 times or not present will be give 'unk' tokens, and if sample have \n",
    "\n",
    "example_tokens=[['Hi', 'I', 'am', \"Akash\"],\n",
    "                ['Hi', \"how\",\"am\",\"are\"],\n",
    "                ['ez','sir']]\n",
    "\n",
    "example_vocab=torchtext.vocab.build_vocab_from_iterator(\n",
    "    example_tokens,\n",
    "    min_freq=min_freq,\n",
    "    specials=special_tokens\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['unk', 'pad', 'Hi', 'am', 'Akash', 'I', 'are', 'ez', 'how', 'sir']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## see the how vocab is used\n",
    "example_vocab.get_itos() ## first vocabs is filled with special tokens, later the most repeated tokens first. If same freq is same then according to alphabetical value "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unk idx : 0\n",
      "Akash:  4\n"
     ]
    }
   ],
   "source": [
    "## Check the IDX value \n",
    "print('unk idx :',example_vocab['unk'])\n",
    "print('Akash: ',example_vocab['Akash'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "## checking if the word is in vocabulary\n",
    "print(\"Akash\" in example_vocab)\n",
    "print(\"akash\" in example_vocab)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Can't access the tokens in vocabs \n"
     ]
    }
   ],
   "source": [
    "## What if the tokens is not in dictionary\n",
    "try:\n",
    "    example_vocab['akash']\n",
    "except:\n",
    "    print(\"Can't access the tokens in vocabs \") \n",
    "\n",
    "## so in order to return 'unk' tokens or 0 value for tokens not in dictionary we have to do thus\n",
    "unk_idx=example_vocab['unk']\n",
    "example_vocab.set_default_index(unk_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_vocab['akash'] ## return 0 for unknown tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 0]\n"
     ]
    }
   ],
   "source": [
    "##list of tokens to indices\n",
    "example_tokens_to_indices=example_vocab.lookup_indices([\"Hi\", \"Nepal\"])\n",
    "print(example_tokens_to_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating Vocabulary on train_data\n",
    "\n",
    "Note: We only create vocabs on train_data; Not on test data so that information is not leaked. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_freq=5\n",
    "special_tokens=['unk','pad'] ## vocabs which appears less than 5 times or not present will be give 'unk' tokens, and if sample have \n",
    "\n",
    "vocab=torchtext.vocab.build_vocab_from_iterator(\n",
    "    train_data['tokens'],\n",
    "    min_freq=min_freq,\n",
    "    specials=special_tokens\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample tokenized example:  ['hello', ',', 'i', 'am', 'from', 'nepal', '!']\n"
     ]
    }
   ],
   "source": [
    "print('sample tokenized example: ',sample_tokenized_text)\n",
    "# print('ids from tokens: ',vocab(sample_tokenized_text)) ## converted to int value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab.set_default_index(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4826"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab['hello']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4826, 4, 12, 219, 44, 20667, 36]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab.lookup_indices(sample_tokenized_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1162,\n",
       " 4,\n",
       " 54,\n",
       " 46,\n",
       " 4,\n",
       " 46,\n",
       " 213,\n",
       " 35,\n",
       " 5,\n",
       " 1031,\n",
       " 7,\n",
       " 2,\n",
       " 37,\n",
       " 65,\n",
       " 223,\n",
       " 1000,\n",
       " 116,\n",
       " 171,\n",
       " 99,\n",
       " 3,\n",
       " 34,\n",
       " 9,\n",
       " 16,\n",
       " 15,\n",
       " 31]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab.lookup_indices(train_data[0]['tokens'])[:25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map:   0%|          | 0/18750 [00:00<?, ? examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 18750/18750 [00:07<00:00, 2366.74 examples/s]\n",
      "Map: 100%|██████████| 6250/6250 [00:02<00:00, 2451.47 examples/s]\n",
      "Map: 100%|██████████| 25000/25000 [00:08<00:00, 2916.71 examples/s]\n"
     ]
    }
   ],
   "source": [
    "## we will add the indices features to train_data\n",
    "\n",
    "def  numericialize_tokens(example,vocab):\n",
    "    ids=vocab.lookup_indices(example['tokens'])\n",
    "    return {'ids':ids}\n",
    "\n",
    "train_data=train_data.map(numericialize_tokens,\n",
    "                          fn_kwargs={'vocab':vocab})\n",
    "\n",
    "\n",
    "val_data=val_data.map(numericialize_tokens,\n",
    "                          fn_kwargs={'vocab':vocab})\n",
    "\n",
    "test_data=test_data.map(numericialize_tokens,\n",
    "                        fn_kwargs={'vocab':vocab})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapped train_data.features:  {'text': Value(dtype='string', id=None), 'label': ClassLabel(names=['neg', 'pos'], id=None), 'tokens': Sequence(feature=Value(dtype='string', id=None), length=-1, id=None), 'ids': Sequence(feature=Value(dtype='int64', id=None), length=-1, id=None)}\n"
     ]
    }
   ],
   "source": [
    "print('mapped train_data.features: ',train_data.features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1162,\n",
       " 4,\n",
       " 54,\n",
       " 46,\n",
       " 4,\n",
       " 46,\n",
       " 213,\n",
       " 35,\n",
       " 5,\n",
       " 1031,\n",
       " 7,\n",
       " 2,\n",
       " 37,\n",
       " 65,\n",
       " 223,\n",
       " 1000,\n",
       " 116,\n",
       " 171,\n",
       " 99,\n",
       " 3,\n",
       " 34,\n",
       " 9,\n",
       " 16,\n",
       " 15,\n",
       " 31]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0]['ids'][:25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "## creatomg tp pytoprch\n",
    "train_data=train_data.with_format(type='torch',columns=['ids','label']) ## convert \"ids\" and \"label\" features to torch format ; Not  other\n",
    "test_data=test_data.with_format(type='torch',columns=['ids','label'])\n",
    "val_data=val_data.with_format(type='torch',columns=['ids','label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_data[0]['ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_collate_fnc(pad_index):\n",
    "    \n",
    "    def collate_fnc(batch):\n",
    "        batch_ids=[i['ids'] for i in batch]\n",
    "        batch_ids=torch.nn.utils.rnn.pad_sequence(batch_ids,padding_value=pad_index,batch_first=True)\n",
    "        batch_label=[i['label'] for i in batch]\n",
    "        batch_label=torch.stack(batch_label)\n",
    "        batch={'ids':batch_ids,'label':batch_label}\n",
    "        return batch\n",
    "    return collate_fnc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "## define Dataloader\n",
    "\n",
    "def get_data_loader(dataset,batch_size,pad_index,shuffle=False):\n",
    "    collate_fnc=get_collate_fnc(pad_index=pad_index)\n",
    "    data_loader=DataLoader(dataset,\n",
    "                           batch_size=batch_size,\n",
    "                           collate_fn=collate_fnc,\n",
    "                           shuffle=shuffle)\n",
    "    return data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "## set shuffle ==True only for train_dataloader\n",
    "batch_size=512\n",
    "pad_idx=0\n",
    "train_data_loader=get_data_loader(train_data,batch_size=batch_size,pad_index=pad_idx,shuffle=True)\n",
    "test_data_loader=get_data_loader(test_data,batch_size=batch_size,pad_index=pad_idx)\n",
    "val_data_loader=get_data_loader(val_data,batch_size=batch_size,pad_index=pad_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512, 256])\n",
      "torch.Size([512, 256])\n",
      "torch.Size([512, 256])\n",
      "torch.Size([512, 256])\n",
      "torch.Size([512, 256])\n",
      "torch.Size([512, 256])\n",
      "torch.Size([512, 256])\n",
      "torch.Size([512, 256])\n",
      "torch.Size([512, 256])\n",
      "torch.Size([512, 256])\n"
     ]
    }
   ],
   "source": [
    "for num,batch in enumerate(train_data_loader):\n",
    "    if num==10:\n",
    "        break\n",
    "\n",
    "    print(batch['ids'].shape)\n",
    "\n",
    "train_data_loader=get_data_loader(train_data,batch_size=batch_size,pad_index=pad_idx,shuffle=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([512, 256])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch['ids'].shape ## batch_size,max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "### defining a Neural Bag of Words\n",
    "class NBoW(nn.Module):\n",
    "\n",
    "    def __init__(self,vocab_size,embedding_dim,output_dim):\n",
    "        super(NBoW,self).__init__()\n",
    "        self.embedding=nn.Embedding(num_embeddings=vocab_size,embedding_dim=embedding_dim) ## return batch_size,num_tokens,emdbedding_dim\n",
    "        self.fc=nn.Linear(in_features=embedding_dim,out_features=output_dim)\n",
    "\n",
    "    def forward(self,x):\n",
    "        embedding_output=self.embedding(x) ## return batch_size,num_tokens,emdbedding_dim\n",
    "        polled_output=embedding_output.mean(dim=1) ## returns batch_size,embedding_dim\n",
    "        prediction=self.fc(polled_output)\n",
    "        return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "## defining the training parameters \n",
    "\n",
    "vocab_size=len(vocab)\n",
    "embedding_dim=300\n",
    "output_dim=len(train_data.unique('label'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ids.shape : torch.Size([512, 256])\n",
      "test_output.shape:  torch.Size([512, 2])\n",
      "real_label.shape\n"
     ]
    }
   ],
   "source": [
    "##testing the model on defined model\n",
    "\n",
    "nbow=NBoW(vocab_size,embedding_dim,output_dim).to(device=device)\n",
    "ids=batch['ids'].to(device=device)\n",
    "print('ids.shape :',ids.shape)\n",
    "\n",
    "test_output=nbow(ids)\n",
    "print('test_output.shape: ',test_output.shape)\n",
    "print('real_label.shape')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=torch.tensor([1,2,3,4,5],dtype=torch.float32)\n",
    "b=torch.tensor([1,2,3,8,9],dtype=torch.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.5000)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.eq(b).sum()/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "## defining accuracy\n",
    "\n",
    "def get_accuracy(prediction,label):\n",
    "    batch_size,_=prediction.shape\n",
    "    prediction_classes=prediction.argmax(dim=1)\n",
    "    corrected_prediction=prediction_classes.eq(label).sum()\n",
    "    accuracy=corrected_prediction/batch_size\n",
    "    return accuracy ## return tnesor as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(data_loader,device,model,criterion,optimizer):\n",
    "    model.train()\n",
    "    epoch_losses=[]\n",
    "    epoch_accuracy=[]\n",
    "\n",
    "    for batch in tqdm.tqdm(data_loader,desc='...........training...........'):\n",
    "        ids=batch['ids'].to(device=device)\n",
    "        label=batch['label'].to(device=device)\n",
    "        prediction=model(ids)\n",
    "        loss=criterion(prediction,label)\n",
    "        accuracy=get_accuracy(prediction,label)\n",
    "        optimizer.zero_grad()\n",
    "        optimizer.step()\n",
    "        epoch_losses.append(loss.item())\n",
    "        epoch_accuracy.append(accuracy.item())\n",
    "\n",
    "    return np.mean(epoch_losses),np.mean(epoch_accuracy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(data_loader,device,model,criterion,optimizer):\n",
    "    model.eval()\n",
    "    epoch_losses=[]\n",
    "    epoch_accuracy=[]\n",
    "\n",
    "    for batch in tqdm.tqdm(data_loader,desc='...........Evaluating...........'):\n",
    "        ids=batch['ids'].to(device=device)\n",
    "        label=batch['label'].to(device=device)\n",
    "        prediction=model(ids)\n",
    "        loss=criterion(prediction,label)\n",
    "        accuracy=get_accuracy(prediction,label)\n",
    "        optimizer.zero_grad()\n",
    "        optimizer.step()\n",
    "        epoch_losses.append(loss.item())\n",
    "        epoch_accuracy.append(accuracy.item())\n",
    "\n",
    "    return np.mean(epoch_losses),np.mean(epoch_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "##defining criterion\n",
    "criterion=nn.CrossEntropyLoss().to(device=device)\n",
    "optimizer=SGD(nbow.parameters(),lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "...........training...........: 100%|██████████| 37/37 [00:01<00:00, 20.95it/s]\n",
      "...........Evaluating...........: 100%|██████████| 13/13 [00:00<00:00, 25.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Num:  0\n",
      "Train Loss: 0.700   | Train Acc: 0.502\n",
      "Val Loss: 0.700   | Val Acc: 0.497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "...........training...........: 100%|██████████| 37/37 [00:01<00:00, 23.42it/s]\n",
      "...........Evaluating...........: 100%|██████████| 13/13 [00:00<00:00, 36.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OKOKOK\n",
      "Epoch Num:  1\n",
      "Train Loss: 0.700   | Train Acc: 0.502\n",
      "Val Loss: 0.700   | Val Acc: 0.497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "...........training...........: 100%|██████████| 37/37 [00:01<00:00, 33.86it/s]\n",
      "...........Evaluating...........: 100%|██████████| 13/13 [00:00<00:00, 36.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OKOKOK\n",
      "Epoch Num:  2\n",
      "Train Loss: 0.700   | Train Acc: 0.502\n",
      "Val Loss: 0.700   | Val Acc: 0.497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "...........training...........: 100%|██████████| 37/37 [00:01<00:00, 31.42it/s]\n",
      "...........Evaluating...........: 100%|██████████| 13/13 [00:00<00:00, 27.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Num:  3\n",
      "Train Loss: 0.700   | Train Acc: 0.502\n",
      "Val Loss: 0.700   | Val Acc: 0.497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "...........training...........: 100%|██████████| 37/37 [00:01<00:00, 21.77it/s]\n",
      "...........Evaluating...........: 100%|██████████| 13/13 [00:00<00:00, 24.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OKOKOK\n",
      "Epoch Num:  4\n",
      "Train Loss: 0.700   | Train Acc: 0.502\n",
      "Val Loss: 0.700   | Val Acc: 0.497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "...........training...........: 100%|██████████| 37/37 [00:01<00:00, 29.51it/s]\n",
      "...........Evaluating...........: 100%|██████████| 13/13 [00:00<00:00, 34.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Num:  5\n",
      "Train Loss: 0.700   | Train Acc: 0.502\n",
      "Val Loss: 0.700   | Val Acc: 0.497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "...........training...........: 100%|██████████| 37/37 [00:01<00:00, 35.75it/s]\n",
      "...........Evaluating...........: 100%|██████████| 13/13 [00:00<00:00, 25.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OKOKOK\n",
      "Epoch Num:  6\n",
      "Train Loss: 0.700   | Train Acc: 0.501\n",
      "Val Loss: 0.700   | Val Acc: 0.497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "...........training...........: 100%|██████████| 37/37 [00:01<00:00, 22.65it/s]\n",
      "...........Evaluating...........: 100%|██████████| 13/13 [00:00<00:00, 25.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OKOKOK\n",
      "Epoch Num:  7\n",
      "Train Loss: 0.700   | Train Acc: 0.502\n",
      "Val Loss: 0.700   | Val Acc: 0.497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "...........training...........: 100%|██████████| 37/37 [00:01<00:00, 24.12it/s]\n",
      "...........Evaluating...........: 100%|██████████| 13/13 [00:00<00:00, 39.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OKOKOK\n",
      "Epoch Num:  8\n",
      "Train Loss: 0.700   | Train Acc: 0.502\n",
      "Val Loss: 0.700   | Val Acc: 0.497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "...........training...........: 100%|██████████| 37/37 [00:00<00:00, 38.15it/s]\n",
      "...........Evaluating...........: 100%|██████████| 13/13 [00:00<00:00, 40.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OKOKOK\n",
      "Epoch Num:  9\n",
      "Train Loss: 0.700   | Train Acc: 0.502\n",
      "Val Loss: 0.700   | Val Acc: 0.497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "...........training...........: 100%|██████████| 37/37 [00:01<00:00, 36.23it/s]\n",
      "...........Evaluating...........: 100%|██████████| 13/13 [00:00<00:00, 38.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OKOKOK\n",
      "Epoch Num:  10\n",
      "Train Loss: 0.700   | Train Acc: 0.502\n",
      "Val Loss: 0.700   | Val Acc: 0.497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "...........training...........: 100%|██████████| 37/37 [00:01<00:00, 33.95it/s]\n",
      "...........Evaluating...........: 100%|██████████| 13/13 [00:00<00:00, 35.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Num:  11\n",
      "Train Loss: 0.700   | Train Acc: 0.502\n",
      "Val Loss: 0.700   | Val Acc: 0.497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "...........training...........: 100%|██████████| 37/37 [00:01<00:00, 24.04it/s]\n",
      "...........Evaluating...........: 100%|██████████| 13/13 [00:00<00:00, 25.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OKOKOK\n",
      "Epoch Num:  12\n",
      "Train Loss: 0.700   | Train Acc: 0.502\n",
      "Val Loss: 0.700   | Val Acc: 0.497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "...........training...........: 100%|██████████| 37/37 [00:01<00:00, 21.96it/s]\n",
      "...........Evaluating...........: 100%|██████████| 13/13 [00:00<00:00, 33.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Num:  13\n",
      "Train Loss: 0.700   | Train Acc: 0.502\n",
      "Val Loss: 0.700   | Val Acc: 0.497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "...........training...........: 100%|██████████| 37/37 [00:00<00:00, 37.34it/s]\n",
      "...........Evaluating...........: 100%|██████████| 13/13 [00:00<00:00, 39.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OKOKOK\n",
      "Epoch Num:  14\n",
      "Train Loss: 0.700   | Train Acc: 0.502\n",
      "Val Loss: 0.700   | Val Acc: 0.497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "...........training...........: 100%|██████████| 37/37 [00:01<00:00, 28.79it/s]\n",
      "...........Evaluating...........: 100%|██████████| 13/13 [00:00<00:00, 26.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OKOKOK\n",
      "Epoch Num:  15\n",
      "Train Loss: 0.700   | Train Acc: 0.502\n",
      "Val Loss: 0.700   | Val Acc: 0.497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "...........training...........: 100%|██████████| 37/37 [00:01<00:00, 31.34it/s]\n",
      "...........Evaluating...........: 100%|██████████| 13/13 [00:00<00:00, 42.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Num:  16\n",
      "Train Loss: 0.700   | Train Acc: 0.502\n",
      "Val Loss: 0.700   | Val Acc: 0.497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "...........training...........: 100%|██████████| 37/37 [00:00<00:00, 39.13it/s]\n",
      "...........Evaluating...........: 100%|██████████| 13/13 [00:00<00:00, 40.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OKOKOK\n",
      "Epoch Num:  17\n",
      "Train Loss: 0.700   | Train Acc: 0.502\n",
      "Val Loss: 0.700   | Val Acc: 0.497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "...........training...........: 100%|██████████| 37/37 [00:01<00:00, 34.35it/s]\n",
      "...........Evaluating...........: 100%|██████████| 13/13 [00:00<00:00, 35.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OKOKOK\n",
      "Epoch Num:  18\n",
      "Train Loss: 0.700   | Train Acc: 0.502\n",
      "Val Loss: 0.700   | Val Acc: 0.497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "...........training...........: 100%|██████████| 37/37 [00:01<00:00, 32.25it/s]\n",
      "...........Evaluating...........: 100%|██████████| 13/13 [00:00<00:00, 31.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Num:  19\n",
      "Train Loss: 0.700   | Train Acc: 0.502\n",
      "Val Loss: 0.700   | Val Acc: 0.497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "...........training...........: 100%|██████████| 37/37 [00:01<00:00, 24.25it/s]\n",
      "...........Evaluating...........: 100%|██████████| 13/13 [00:00<00:00, 25.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OKOKOK\n",
      "Epoch Num:  20\n",
      "Train Loss: 0.700   | Train Acc: 0.502\n",
      "Val Loss: 0.700   | Val Acc: 0.497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "...........training...........: 100%|██████████| 37/37 [00:01<00:00, 25.47it/s]\n",
      "...........Evaluating...........: 100%|██████████| 13/13 [00:00<00:00, 40.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OKOKOK\n",
      "Epoch Num:  21\n",
      "Train Loss: 0.700   | Train Acc: 0.502\n",
      "Val Loss: 0.700   | Val Acc: 0.497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "...........training...........: 100%|██████████| 37/37 [00:01<00:00, 32.29it/s]\n",
      "...........Evaluating...........: 100%|██████████| 13/13 [00:00<00:00, 40.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OKOKOK\n",
      "Epoch Num:  22\n",
      "Train Loss: 0.700   | Train Acc: 0.502\n",
      "Val Loss: 0.700   | Val Acc: 0.497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "...........training...........: 100%|██████████| 37/37 [00:01<00:00, 33.62it/s]\n",
      "...........Evaluating...........: 100%|██████████| 13/13 [00:00<00:00, 35.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Num:  23\n",
      "Train Loss: 0.700   | Train Acc: 0.502\n",
      "Val Loss: 0.700   | Val Acc: 0.497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "...........training...........: 100%|██████████| 37/37 [00:01<00:00, 33.17it/s]\n",
      "...........Evaluating...........: 100%|██████████| 13/13 [00:00<00:00, 27.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OKOKOK\n",
      "Epoch Num:  24\n",
      "Train Loss: 0.700   | Train Acc: 0.502\n",
      "Val Loss: 0.700   | Val Acc: 0.497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "...........training...........: 100%|██████████| 37/37 [00:01<00:00, 23.75it/s]\n",
      "...........Evaluating...........: 100%|██████████| 13/13 [00:00<00:00, 27.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OKOKOK\n",
      "Epoch Num:  25\n",
      "Train Loss: 0.700   | Train Acc: 0.502\n",
      "Val Loss: 0.700   | Val Acc: 0.497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "...........training...........: 100%|██████████| 37/37 [00:01<00:00, 29.74it/s]\n",
      "...........Evaluating...........: 100%|██████████| 13/13 [00:00<00:00, 39.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Num:  26\n",
      "Train Loss: 0.700   | Train Acc: 0.502\n",
      "Val Loss: 0.700   | Val Acc: 0.497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "...........training...........: 100%|██████████| 37/37 [00:01<00:00, 35.67it/s]\n",
      "...........Evaluating...........: 100%|██████████| 13/13 [00:00<00:00, 24.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OKOKOK\n",
      "Epoch Num:  27\n",
      "Train Loss: 0.700   | Train Acc: 0.502\n",
      "Val Loss: 0.700   | Val Acc: 0.497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "...........training...........: 100%|██████████| 37/37 [00:01<00:00, 26.83it/s]\n",
      "...........Evaluating...........: 100%|██████████| 13/13 [00:00<00:00, 39.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OKOKOK\n",
      "Epoch Num:  28\n",
      "Train Loss: 0.700   | Train Acc: 0.502\n",
      "Val Loss: 0.700   | Val Acc: 0.497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "...........training...........: 100%|██████████| 37/37 [00:00<00:00, 37.11it/s]\n",
      "...........Evaluating...........: 100%|██████████| 13/13 [00:00<00:00, 38.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OKOKOK\n",
      "Epoch Num:  29\n",
      "Train Loss: 0.700   | Train Acc: 0.502\n",
      "Val Loss: 0.700   | Val Acc: 0.497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "...........training...........: 100%|██████████| 37/37 [00:01<00:00, 34.86it/s]\n",
      "...........Evaluating...........: 100%|██████████| 13/13 [00:00<00:00, 33.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OKOKOK\n",
      "Epoch Num:  30\n",
      "Train Loss: 0.700   | Train Acc: 0.502\n",
      "Val Loss: 0.700   | Val Acc: 0.497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "...........training...........: 100%|██████████| 37/37 [00:01<00:00, 26.49it/s]\n",
      "...........Evaluating...........: 100%|██████████| 13/13 [00:00<00:00, 24.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OKOKOK\n",
      "Epoch Num:  31\n",
      "Train Loss: 0.700   | Train Acc: 0.502\n",
      "Val Loss: 0.700   | Val Acc: 0.497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "...........training...........: 100%|██████████| 37/37 [00:01<00:00, 23.30it/s]\n",
      "...........Evaluating...........: 100%|██████████| 13/13 [00:00<00:00, 27.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OKOKOK\n",
      "Epoch Num:  32\n",
      "Train Loss: 0.700   | Train Acc: 0.502\n",
      "Val Loss: 0.700   | Val Acc: 0.497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "...........training...........: 100%|██████████| 37/37 [00:01<00:00, 31.50it/s]\n",
      "...........Evaluating...........: 100%|██████████| 13/13 [00:00<00:00, 40.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Num:  33\n",
      "Train Loss: 0.700   | Train Acc: 0.502\n",
      "Val Loss: 0.700   | Val Acc: 0.497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "...........training...........: 100%|██████████| 37/37 [00:01<00:00, 35.87it/s]\n",
      "...........Evaluating...........: 100%|██████████| 13/13 [00:00<00:00, 36.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OKOKOK\n",
      "Epoch Num:  34\n",
      "Train Loss: 0.700   | Train Acc: 0.502\n",
      "Val Loss: 0.700   | Val Acc: 0.497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "...........training...........: 100%|██████████| 37/37 [00:01<00:00, 33.73it/s]\n",
      "...........Evaluating...........: 100%|██████████| 13/13 [00:00<00:00, 35.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Num:  35\n",
      "Train Loss: 0.700   | Train Acc: 0.503\n",
      "Val Loss: 0.700   | Val Acc: 0.497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "...........training...........: 100%|██████████| 37/37 [00:01<00:00, 32.62it/s]\n",
      "...........Evaluating...........: 100%|██████████| 13/13 [00:00<00:00, 25.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OKOKOK\n",
      "Epoch Num:  36\n",
      "Train Loss: 0.700   | Train Acc: 0.502\n",
      "Val Loss: 0.700   | Val Acc: 0.497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "...........training...........: 100%|██████████| 37/37 [00:01<00:00, 23.35it/s]\n",
      "...........Evaluating...........: 100%|██████████| 13/13 [00:00<00:00, 27.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OKOKOK\n",
      "Epoch Num:  37\n",
      "Train Loss: 0.700   | Train Acc: 0.502\n",
      "Val Loss: 0.700   | Val Acc: 0.497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "...........training...........: 100%|██████████| 37/37 [00:01<00:00, 35.46it/s]\n",
      "...........Evaluating...........: 100%|██████████| 13/13 [00:00<00:00, 41.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OKOKOK\n",
      "Epoch Num:  38\n",
      "Train Loss: 0.700   | Train Acc: 0.502\n",
      "Val Loss: 0.700   | Val Acc: 0.497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "...........training...........: 100%|██████████| 37/37 [00:00<00:00, 38.12it/s]\n",
      "...........Evaluating...........: 100%|██████████| 13/13 [00:00<00:00, 36.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OKOKOK\n",
      "Epoch Num:  39\n",
      "Train Loss: 0.700   | Train Acc: 0.502\n",
      "Val Loss: 0.700   | Val Acc: 0.497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "...........training...........: 100%|██████████| 37/37 [00:01<00:00, 31.18it/s]\n",
      "...........Evaluating...........: 100%|██████████| 13/13 [00:00<00:00, 36.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Num:  40\n",
      "Train Loss: 0.700   | Train Acc: 0.502\n",
      "Val Loss: 0.700   | Val Acc: 0.497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "...........training...........: 100%|██████████| 37/37 [00:01<00:00, 23.89it/s]\n",
      "...........Evaluating...........: 100%|██████████| 13/13 [00:00<00:00, 26.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OKOKOK\n",
      "Epoch Num:  41\n",
      "Train Loss: 0.700   | Train Acc: 0.502\n",
      "Val Loss: 0.700   | Val Acc: 0.497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "...........training...........: 100%|██████████| 37/37 [00:01<00:00, 34.16it/s]\n",
      "...........Evaluating...........: 100%|██████████| 13/13 [00:00<00:00, 41.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OKOKOK\n",
      "Epoch Num:  42\n",
      "Train Loss: 0.700   | Train Acc: 0.502\n",
      "Val Loss: 0.700   | Val Acc: 0.497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "...........training...........: 100%|██████████| 37/37 [00:00<00:00, 39.25it/s]\n",
      "...........Evaluating...........: 100%|██████████| 13/13 [00:00<00:00, 30.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OKOKOK\n",
      "Epoch Num:  43\n",
      "Train Loss: 0.700   | Train Acc: 0.502\n",
      "Val Loss: 0.700   | Val Acc: 0.497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "...........training...........: 100%|██████████| 37/37 [00:01<00:00, 28.69it/s]\n",
      "...........Evaluating...........: 100%|██████████| 13/13 [00:00<00:00, 42.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OKOKOK\n",
      "Epoch Num:  44\n",
      "Train Loss: 0.700   | Train Acc: 0.502\n",
      "Val Loss: 0.700   | Val Acc: 0.497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "...........training...........: 100%|██████████| 37/37 [00:00<00:00, 39.25it/s]\n",
      "...........Evaluating...........: 100%|██████████| 13/13 [00:00<00:00, 40.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Num:  45\n",
      "Train Loss: 0.700   | Train Acc: 0.502\n",
      "Val Loss: 0.700   | Val Acc: 0.497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "...........training...........: 100%|██████████| 37/37 [00:01<00:00, 25.88it/s]\n",
      "...........Evaluating...........: 100%|██████████| 13/13 [00:00<00:00, 26.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Num:  46\n",
      "Train Loss: 0.700   | Train Acc: 0.502\n",
      "Val Loss: 0.700   | Val Acc: 0.497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "...........training...........: 100%|██████████| 37/37 [00:01<00:00, 27.09it/s]\n",
      "...........Evaluating...........: 100%|██████████| 13/13 [00:00<00:00, 38.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OKOKOK\n",
      "Epoch Num:  47\n",
      "Train Loss: 0.700   | Train Acc: 0.502\n",
      "Val Loss: 0.700   | Val Acc: 0.497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "...........training...........: 100%|██████████| 37/37 [00:00<00:00, 38.63it/s]\n",
      "...........Evaluating...........: 100%|██████████| 13/13 [00:00<00:00, 39.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OKOKOK\n",
      "Epoch Num:  48\n",
      "Train Loss: 0.700   | Train Acc: 0.502\n",
      "Val Loss: 0.700   | Val Acc: 0.497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "...........training...........: 100%|██████████| 37/37 [00:01<00:00, 31.20it/s]\n",
      "...........Evaluating...........: 100%|██████████| 13/13 [00:00<00:00, 36.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OKOKOK\n",
      "Epoch Num:  49\n",
      "Train Loss: 0.700   | Train Acc: 0.502\n",
      "Val Loss: 0.700   | Val Acc: 0.497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "...........training...........: 100%|██████████| 37/37 [00:01<00:00, 34.01it/s]\n",
      "...........Evaluating...........: 100%|██████████| 13/13 [00:00<00:00, 36.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OKOKOK\n",
      "Epoch Num:  50\n",
      "Train Loss: 0.700   | Train Acc: 0.502\n",
      "Val Loss: 0.700   | Val Acc: 0.497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "...........training...........: 100%|██████████| 37/37 [00:01<00:00, 25.76it/s]\n",
      "...........Evaluating...........: 100%|██████████| 13/13 [00:00<00:00, 26.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OKOKOK\n",
      "Epoch Num:  51\n",
      "Train Loss: 0.700   | Train Acc: 0.502\n",
      "Val Loss: 0.700   | Val Acc: 0.497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "...........training...........: 100%|██████████| 37/37 [00:01<00:00, 32.98it/s]\n",
      "...........Evaluating...........: 100%|██████████| 13/13 [00:00<00:00, 41.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OKOKOK\n",
      "Epoch Num:  52\n",
      "Train Loss: 0.700   | Train Acc: 0.502\n",
      "Val Loss: 0.700   | Val Acc: 0.497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "...........training...........: 100%|██████████| 37/37 [00:00<00:00, 38.96it/s]\n",
      "...........Evaluating...........: 100%|██████████| 13/13 [00:00<00:00, 38.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OKOKOK\n",
      "Epoch Num:  53\n",
      "Train Loss: 0.700   | Train Acc: 0.502\n",
      "Val Loss: 0.700   | Val Acc: 0.497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "...........training...........: 100%|██████████| 37/37 [00:01<00:00, 35.93it/s]\n",
      "...........Evaluating...........: 100%|██████████| 13/13 [00:00<00:00, 37.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OKOKOK\n",
      "Epoch Num:  54\n",
      "Train Loss: 0.700   | Train Acc: 0.502\n",
      "Val Loss: 0.700   | Val Acc: 0.497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "...........training...........: 100%|██████████| 37/37 [00:01<00:00, 34.43it/s]\n",
      "...........Evaluating...........: 100%|██████████| 13/13 [00:00<00:00, 34.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OKOKOK\n",
      "Epoch Num:  55\n",
      "Train Loss: 0.700   | Train Acc: 0.502\n",
      "Val Loss: 0.700   | Val Acc: 0.497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "...........training...........: 100%|██████████| 37/37 [00:01<00:00, 25.00it/s]\n",
      "...........Evaluating...........: 100%|██████████| 13/13 [00:00<00:00, 27.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Num:  56\n",
      "Train Loss: 0.700   | Train Acc: 0.503\n",
      "Val Loss: 0.700   | Val Acc: 0.497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "...........training...........: 100%|██████████| 37/37 [00:01<00:00, 35.86it/s]\n",
      "...........Evaluating...........: 100%|██████████| 13/13 [00:00<00:00, 43.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Num:  57\n",
      "Train Loss: 0.700   | Train Acc: 0.502\n",
      "Val Loss: 0.700   | Val Acc: 0.497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "...........training...........: 100%|██████████| 37/37 [00:01<00:00, 33.30it/s]\n",
      "...........Evaluating...........: 100%|██████████| 13/13 [00:00<00:00, 37.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OKOKOK\n",
      "Epoch Num:  58\n",
      "Train Loss: 0.700   | Train Acc: 0.502\n",
      "Val Loss: 0.700   | Val Acc: 0.497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "...........training...........: 100%|██████████| 37/37 [00:01<00:00, 34.32it/s]\n",
      "...........Evaluating...........: 100%|██████████| 13/13 [00:00<00:00, 36.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OKOKOK\n",
      "Epoch Num:  59\n",
      "Train Loss: 0.700   | Train Acc: 0.502\n",
      "Val Loss: 0.700   | Val Acc: 0.497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "...........training...........: 100%|██████████| 37/37 [00:01<00:00, 34.71it/s]\n",
      "...........Evaluating...........: 100%|██████████| 13/13 [00:00<00:00, 37.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Num:  60\n",
      "Train Loss: 0.700   | Train Acc: 0.502\n",
      "Val Loss: 0.700   | Val Acc: 0.497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "...........training...........: 100%|██████████| 37/37 [00:01<00:00, 23.70it/s]\n",
      "...........Evaluating...........: 100%|██████████| 13/13 [00:00<00:00, 24.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OKOKOK\n",
      "Epoch Num:  61\n",
      "Train Loss: 0.700   | Train Acc: 0.502\n",
      "Val Loss: 0.700   | Val Acc: 0.497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "...........training...........: 100%|██████████| 37/37 [00:01<00:00, 23.15it/s]\n",
      "...........Evaluating...........: 100%|██████████| 13/13 [00:00<00:00, 24.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OKOKOK\n",
      "Epoch Num:  62\n",
      "Train Loss: 0.700   | Train Acc: 0.502\n",
      "Val Loss: 0.700   | Val Acc: 0.497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "...........training...........: 100%|██████████| 37/37 [00:01<00:00, 24.18it/s]\n",
      "...........Evaluating...........: 100%|██████████| 13/13 [00:00<00:00, 37.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Num:  63\n",
      "Train Loss: 0.700   | Train Acc: 0.502\n",
      "Val Loss: 0.700   | Val Acc: 0.497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "...........training...........: 100%|██████████| 37/37 [00:01<00:00, 32.96it/s]\n",
      "...........Evaluating...........: 100%|██████████| 13/13 [00:00<00:00, 36.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OKOKOK\n",
      "Epoch Num:  64\n",
      "Train Loss: 0.700   | Train Acc: 0.502\n",
      "Val Loss: 0.700   | Val Acc: 0.497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "...........training...........: 100%|██████████| 37/37 [00:01<00:00, 23.98it/s]\n",
      "...........Evaluating...........: 100%|██████████| 13/13 [00:00<00:00, 25.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OKOKOK\n",
      "Epoch Num:  65\n",
      "Train Loss: 0.700   | Train Acc: 0.502\n",
      "Val Loss: 0.700   | Val Acc: 0.497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "...........training...........: 100%|██████████| 37/37 [00:01<00:00, 24.31it/s]\n",
      "...........Evaluating...........: 100%|██████████| 13/13 [00:00<00:00, 37.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Num:  66\n",
      "Train Loss: 0.700   | Train Acc: 0.502\n",
      "Val Loss: 0.700   | Val Acc: 0.497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "...........training...........: 100%|██████████| 37/37 [00:01<00:00, 31.89it/s]\n",
      "...........Evaluating...........: 100%|██████████| 13/13 [00:00<00:00, 35.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OKOKOK\n",
      "Epoch Num:  67\n",
      "Train Loss: 0.700   | Train Acc: 0.502\n",
      "Val Loss: 0.700   | Val Acc: 0.497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "...........training...........: 100%|██████████| 37/37 [00:01<00:00, 33.73it/s]\n",
      "...........Evaluating...........: 100%|██████████| 13/13 [00:00<00:00, 35.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Num:  68\n",
      "Train Loss: 0.700   | Train Acc: 0.503\n",
      "Val Loss: 0.700   | Val Acc: 0.497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "...........training...........: 100%|██████████| 37/37 [00:01<00:00, 31.79it/s]\n",
      "...........Evaluating...........: 100%|██████████| 13/13 [00:00<00:00, 30.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Num:  69\n",
      "Train Loss: 0.700   | Train Acc: 0.502\n",
      "Val Loss: 0.700   | Val Acc: 0.497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "...........training...........: 100%|██████████| 37/37 [00:01<00:00, 23.50it/s]\n",
      "...........Evaluating...........: 100%|██████████| 13/13 [00:00<00:00, 26.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Num:  70\n",
      "Train Loss: 0.700   | Train Acc: 0.503\n",
      "Val Loss: 0.700   | Val Acc: 0.497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "...........training...........: 100%|██████████| 37/37 [00:01<00:00, 26.13it/s]\n",
      "...........Evaluating...........: 100%|██████████| 13/13 [00:00<00:00, 40.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OKOKOK\n",
      "Epoch Num:  71\n",
      "Train Loss: 0.700   | Train Acc: 0.502\n",
      "Val Loss: 0.700   | Val Acc: 0.497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "...........training...........: 100%|██████████| 37/37 [00:01<00:00, 36.56it/s]\n",
      "...........Evaluating...........: 100%|██████████| 13/13 [00:00<00:00, 38.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OKOKOK\n",
      "Epoch Num:  72\n",
      "Train Loss: 0.700   | Train Acc: 0.502\n",
      "Val Loss: 0.700   | Val Acc: 0.497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "...........training...........: 100%|██████████| 37/37 [00:01<00:00, 34.19it/s]\n",
      "...........Evaluating...........: 100%|██████████| 13/13 [00:00<00:00, 35.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OKOKOK\n",
      "Epoch Num:  73\n",
      "Train Loss: 0.700   | Train Acc: 0.502\n",
      "Val Loss: 0.700   | Val Acc: 0.497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "...........training...........: 100%|██████████| 37/37 [00:01<00:00, 32.93it/s]\n",
      "...........Evaluating...........: 100%|██████████| 13/13 [00:00<00:00, 33.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Num:  74\n",
      "Train Loss: 0.700   | Train Acc: 0.502\n",
      "Val Loss: 0.700   | Val Acc: 0.497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "...........training...........: 100%|██████████| 37/37 [00:01<00:00, 23.06it/s]\n",
      "...........Evaluating...........: 100%|██████████| 13/13 [00:00<00:00, 24.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OKOKOK\n",
      "Epoch Num:  75\n",
      "Train Loss: 0.700   | Train Acc: 0.502\n",
      "Val Loss: 0.700   | Val Acc: 0.497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "...........training...........: 100%|██████████| 37/37 [00:01<00:00, 20.90it/s]\n",
      "...........Evaluating...........: 100%|██████████| 13/13 [00:00<00:00, 33.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Num:  76\n",
      "Train Loss: 0.700   | Train Acc: 0.502\n",
      "Val Loss: 0.700   | Val Acc: 0.497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "...........training...........: 100%|██████████| 37/37 [00:01<00:00, 35.87it/s]\n",
      "...........Evaluating...........: 100%|██████████| 13/13 [00:00<00:00, 38.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OKOKOK\n",
      "Epoch Num:  77\n",
      "Train Loss: 0.700   | Train Acc: 0.502\n",
      "Val Loss: 0.700   | Val Acc: 0.497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "...........training...........: 100%|██████████| 37/37 [00:01<00:00, 34.38it/s]\n",
      "...........Evaluating...........: 100%|██████████| 13/13 [00:00<00:00, 34.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OKOKOK\n",
      "Epoch Num:  78\n",
      "Train Loss: 0.700   | Train Acc: 0.502\n",
      "Val Loss: 0.700   | Val Acc: 0.497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "...........training...........: 100%|██████████| 37/37 [00:01<00:00, 32.31it/s]\n",
      "...........Evaluating...........: 100%|██████████| 13/13 [00:00<00:00, 35.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Num:  79\n",
      "Train Loss: 0.700   | Train Acc: 0.503\n",
      "Val Loss: 0.700   | Val Acc: 0.497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "...........training...........: 100%|██████████| 37/37 [00:01<00:00, 24.09it/s]\n",
      "...........Evaluating...........: 100%|██████████| 13/13 [00:00<00:00, 25.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OKOKOK\n",
      "Epoch Num:  80\n",
      "Train Loss: 0.700   | Train Acc: 0.502\n",
      "Val Loss: 0.700   | Val Acc: 0.497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "...........training...........: 100%|██████████| 37/37 [00:01<00:00, 23.35it/s]\n",
      "...........Evaluating...........: 100%|██████████| 13/13 [00:00<00:00, 24.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Num:  81\n",
      "Train Loss: 0.700   | Train Acc: 0.502\n",
      "Val Loss: 0.700   | Val Acc: 0.497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "...........training...........: 100%|██████████| 37/37 [00:01<00:00, 26.64it/s]\n",
      "...........Evaluating...........: 100%|██████████| 13/13 [00:00<00:00, 38.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OKOKOK\n",
      "Epoch Num:  82\n",
      "Train Loss: 0.700   | Train Acc: 0.502\n",
      "Val Loss: 0.700   | Val Acc: 0.497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "...........training...........: 100%|██████████| 37/37 [00:01<00:00, 34.96it/s]\n",
      "...........Evaluating...........: 100%|██████████| 13/13 [00:00<00:00, 29.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Num:  83\n",
      "Train Loss: 0.700   | Train Acc: 0.502\n",
      "Val Loss: 0.700   | Val Acc: 0.497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "...........training...........: 100%|██████████| 37/37 [00:01<00:00, 22.90it/s]\n",
      "...........Evaluating...........: 100%|██████████| 13/13 [00:00<00:00, 24.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OKOKOK\n",
      "Epoch Num:  84\n",
      "Train Loss: 0.700   | Train Acc: 0.502\n",
      "Val Loss: 0.700   | Val Acc: 0.497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "...........training...........: 100%|██████████| 37/37 [00:01<00:00, 20.53it/s]\n",
      "...........Evaluating...........: 100%|██████████| 13/13 [00:00<00:00, 24.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Num:  85\n",
      "Train Loss: 0.700   | Train Acc: 0.502\n",
      "Val Loss: 0.700   | Val Acc: 0.497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "...........training...........: 100%|██████████| 37/37 [00:01<00:00, 27.60it/s]\n",
      "...........Evaluating...........: 100%|██████████| 13/13 [00:00<00:00, 41.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Num:  86\n",
      "Train Loss: 0.700   | Train Acc: 0.503\n",
      "Val Loss: 0.700   | Val Acc: 0.497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "...........training...........: 100%|██████████| 37/37 [00:01<00:00, 35.19it/s]\n",
      "...........Evaluating...........: 100%|██████████| 13/13 [00:00<00:00, 33.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OKOKOK\n",
      "Epoch Num:  87\n",
      "Train Loss: 0.700   | Train Acc: 0.502\n",
      "Val Loss: 0.700   | Val Acc: 0.497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "...........training...........: 100%|██████████| 37/37 [00:01<00:00, 23.85it/s]\n",
      "...........Evaluating...........: 100%|██████████| 13/13 [00:00<00:00, 29.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OKOKOK\n",
      "Epoch Num:  88\n",
      "Train Loss: 0.700   | Train Acc: 0.502\n",
      "Val Loss: 0.700   | Val Acc: 0.497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "...........training...........: 100%|██████████| 37/37 [00:01<00:00, 35.32it/s]\n",
      "...........Evaluating...........: 100%|██████████| 13/13 [00:00<00:00, 37.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OKOKOK\n",
      "Epoch Num:  89\n",
      "Train Loss: 0.700   | Train Acc: 0.502\n",
      "Val Loss: 0.700   | Val Acc: 0.497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "...........training...........: 100%|██████████| 37/37 [00:01<00:00, 34.51it/s]\n",
      "...........Evaluating...........: 100%|██████████| 13/13 [00:00<00:00, 34.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OKOKOK\n",
      "Epoch Num:  90\n",
      "Train Loss: 0.700   | Train Acc: 0.502\n",
      "Val Loss: 0.700   | Val Acc: 0.497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "...........training...........: 100%|██████████| 37/37 [00:01<00:00, 27.85it/s]\n",
      "...........Evaluating...........: 100%|██████████| 13/13 [00:00<00:00, 24.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Num:  91\n",
      "Train Loss: 0.700   | Train Acc: 0.502\n",
      "Val Loss: 0.700   | Val Acc: 0.497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "...........training...........: 100%|██████████| 37/37 [00:01<00:00, 26.36it/s]\n",
      "...........Evaluating...........: 100%|██████████| 13/13 [00:00<00:00, 40.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Num:  92\n",
      "Train Loss: 0.700   | Train Acc: 0.502\n",
      "Val Loss: 0.700   | Val Acc: 0.497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "...........training...........: 100%|██████████| 37/37 [00:01<00:00, 36.38it/s]\n",
      "...........Evaluating...........: 100%|██████████| 13/13 [00:00<00:00, 31.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OKOKOK\n",
      "Epoch Num:  93\n",
      "Train Loss: 0.700   | Train Acc: 0.502\n",
      "Val Loss: 0.700   | Val Acc: 0.497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "...........training...........: 100%|██████████| 37/37 [00:01<00:00, 28.37it/s]\n",
      "...........Evaluating...........: 100%|██████████| 13/13 [00:00<00:00, 24.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Num:  94\n",
      "Train Loss: 0.700   | Train Acc: 0.502\n",
      "Val Loss: 0.700   | Val Acc: 0.497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "...........training...........: 100%|██████████| 37/37 [00:01<00:00, 23.53it/s]\n",
      "...........Evaluating...........: 100%|██████████| 13/13 [00:00<00:00, 26.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OKOKOK\n",
      "Epoch Num:  95\n",
      "Train Loss: 0.700   | Train Acc: 0.502\n",
      "Val Loss: 0.700   | Val Acc: 0.497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "...........training...........: 100%|██████████| 37/37 [00:01<00:00, 35.67it/s]\n",
      "...........Evaluating...........: 100%|██████████| 13/13 [00:00<00:00, 39.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Num:  96\n",
      "Train Loss: 0.700   | Train Acc: 0.502\n",
      "Val Loss: 0.700   | Val Acc: 0.497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "...........training...........: 100%|██████████| 37/37 [00:01<00:00, 29.39it/s]\n",
      "...........Evaluating...........: 100%|██████████| 13/13 [00:00<00:00, 27.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OKOKOK\n",
      "Epoch Num:  97\n",
      "Train Loss: 0.700   | Train Acc: 0.501\n",
      "Val Loss: 0.700   | Val Acc: 0.497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "...........training...........: 100%|██████████| 37/37 [00:01<00:00, 30.24it/s]\n",
      "...........Evaluating...........: 100%|██████████| 13/13 [00:00<00:00, 37.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Num:  98\n",
      "Train Loss: 0.700   | Train Acc: 0.502\n",
      "Val Loss: 0.700   | Val Acc: 0.497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "...........training...........: 100%|██████████| 37/37 [00:01<00:00, 36.50it/s]\n",
      "...........Evaluating...........: 100%|██████████| 13/13 [00:00<00:00, 24.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OKOKOK\n",
      "Epoch Num:  99\n",
      "Train Loss: 0.700   | Train Acc: 0.502\n",
      "Val Loss: 0.700   | Val Acc: 0.497\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'_IncompatibleKeys' object has no attribute 'to'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[88], line 35\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mVal Loss: \u001b[39m\u001b[38;5;132;01m{:.3f}\u001b[39;00m\u001b[38;5;124m   | Val Acc: \u001b[39m\u001b[38;5;132;01m{:.3f}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(val_loss,val_acc))\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m## best Validation loss\u001b[39;00m\n\u001b[0;32m---> 35\u001b[0m \u001b[43mnbow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43msave_dire\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m(device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[1;32m     36\u001b[0m best_val_loss,best_val_acc\u001b[38;5;241m=\u001b[39mevaluate(val_data_loader,device\u001b[38;5;241m=\u001b[39mdevice,\n\u001b[1;32m     37\u001b[0m                                   model\u001b[38;5;241m=\u001b[39mnbow,criterion\u001b[38;5;241m=\u001b[39mcriterion,\n\u001b[1;32m     38\u001b[0m                                   optimizer\u001b[38;5;241m=\u001b[39moptimizer)\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBest Val Loss: \u001b[39m\u001b[38;5;132;01m{:.3f}\u001b[39;00m\u001b[38;5;124m   | Best Val Acc: \u001b[39m\u001b[38;5;132;01m{:.3f}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(best_val_loss,best_val_acc))\n",
      "\u001b[0;31mAttributeError\u001b[0m: '_IncompatibleKeys' object has no attribute 'to'"
     ]
    }
   ],
   "source": [
    "save_dire=\"../saved_model/nbow.pt\"\n",
    "n_epochs=100\n",
    "best_valid_loss=float(\"inf\")\n",
    "\n",
    "metrics=collections.defaultdict(list)\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    train_loss,train_acc=training(train_data_loader,device=device,\n",
    "                                  model=nbow,criterion=criterion,\n",
    "                                  optimizer=optimizer)\n",
    "    \n",
    "    val_loss,val_acc=evaluate(val_data_loader,device=device,\n",
    "                                  model=nbow,criterion=criterion,\n",
    "                                  optimizer=optimizer)\n",
    "    \n",
    "    metrics['train_loss'].append(train_loss)\n",
    "    metrics['train_acc'].append(train_acc)\n",
    "    metrics['val_loss'].append(val_loss)\n",
    "    metrics['val_acc'].append(val_acc)\n",
    "    if val_loss<train_loss:\n",
    "        print('OKOKOK')\n",
    "        best_valid_loss=val_loss\n",
    "        \n",
    "        torch.save(nbow.state_dict(),save_dire)\n",
    "\n",
    "    print(\"Epoch Num: \", epoch)\n",
    "    print('Train Loss: {:.3f}   | Train Acc: {:.3f}'.format(train_loss,train_acc))\n",
    "    print('Val Loss: {:.3f}   | Val Acc: {:.3f}'.format(val_loss,val_acc))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## best Validation loss\n",
    "\n",
    "nbow.load_state_dict(torch.load(save_dire)).to(device=device)\n",
    "best_val_loss,best_val_acc=evaluate(val_data_loader,device=device,\n",
    "                                  model=nbow,criterion=criterion,\n",
    "                                  optimizer=optimizer)\n",
    "\n",
    "print('Best Val Loss: {:.3f}   | Best Val Acc: {:.3f}'.format(best_val_loss,best_val_acc))\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('../saved_model/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vision",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
