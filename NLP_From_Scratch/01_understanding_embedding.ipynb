{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding Layer Understanding\n",
    "\n",
    "### Embedding Layer Setup\n",
    "\n",
    "- **Define an Embedding Layer**:\n",
    "  - `num_embeddings = 6`: Vocabulary size (number of unique tokens)\n",
    "  - `embedding_dim = 4`: Dimension of each embedding vector\n",
    "  - The embedding matrix (denoted as `E`) will have a shape of `[6, 4]`.\n",
    "\n",
    "- **Embedding Matrix `E`**:\n",
    "```\n",
    "E = | 0.1 0.2 0.3 0.4 | # Embedding for token 0\n",
    "| 0.5 0.6 0.7 0.8 | # Embedding for token 1\n",
    "| 0.9 1.0 1.1 1.2 | # Embedding for token 2\n",
    "| 1.3 1.4 1.5 1.6 | # Embedding for token 3\n",
    "| 1.7 1.8 1.9 2.0 | # Embedding for token 4\n",
    "| 2.1 2.2 2.3 2.4 | # Embedding for token 5\n",
    "```\n",
    "\n",
    "\n",
    "*In pytorch it we can create learnable Embedding matrix as:*\n",
    "```python\n",
    "from torch.nn import Embedding\n",
    "\n",
    "emb_layers=Embedding(num_embeddings=6,embedding_dim=4) ##num_embedding is equal to to vocab_size\n",
    "```\n",
    "\n",
    "- Shape of `E`: `[6, 4]`\n",
    "\n",
    "### Sample Input and Embedding Lookup\n",
    "\n",
    "- **Sample Input**:\n",
    "- `input_indices = [[1, 4, 3], [2, 0, 5]]`\n",
    "- Shape of `input_indices`: `[2, 3]` (2 sequences, each with 3 tokens)\n",
    "\n",
    "- **Performing the Lookup**:\n",
    "- Each index in `input_indices` is mapped to its corresponding embedding vector in `E`.\n",
    "\n",
    "- **Output**:\n",
    "- Each index is replaced by its corresponding 4-dimensional embedding vector.\n",
    "- Output for `input_indices[0] = [1, 4, 3]`:\n",
    "  ```\n",
    "  | 0.5  0.6  0.7  0.8 |   # Embedding for token 1\n",
    "  | 1.7  1.8  1.9  2.0 |   # Embedding for token 4\n",
    "  | 1.3  1.4  1.5  1.6 |   # Embedding for token 3\n",
    "  ```\n",
    "- Output for `input_indices[1] = [2, 0, 5]`:\n",
    "  ```\n",
    "  | 0.9  1.0  1.1  1.2 |   # Embedding for token 2\n",
    "  | 0.1  0.2  0.3  0.4 |   # Embedding for token 0\n",
    "  | 2.1  2.2  2.3  2.4 |   # Embedding for token 5\n",
    "  ```\n",
    "- Shape of Output: `[2, 3, 4]` (2 sequences, each with 3 tokens, each represented by a 4-dimensional vector)\n",
    "\n",
    "### Summary\n",
    "\n",
    "- The embedding matrix `E` is shaped `[num_embeddings, embedding_dim]`, `[6, 4]` in this example.\n",
    "- The input indices are shaped `[batch_size, sequence_length]`, `[2, 3]` here.\n",
    "- The output of the embedding layer is shaped `[batch_size, sequence_length, embedding_dim]`, `[2, 3, 4]` in this case, with each token index replaced by its corresponding embedding vector.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type:  torch.int64\n",
      "shape:   torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "##creating a simple tensor; 2 sentence with 3 tokesn length\n",
    "\n",
    "input_example=torch.LongTensor([[1,3,4],[2,6,8]])\n",
    "print('type: ',input_example.dtype)\n",
    "print('shape:  ',input_example.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emd_layer:   tensor([[[ 0.3479,  1.6453, -0.5427, -1.1865, -0.6854],\n",
      "         [ 0.3126, -0.1501, -0.3753,  1.3835,  0.8567],\n",
      "         [ 1.0775,  0.9205, -0.1192,  0.0075, -0.4301]],\n",
      "\n",
      "        [[ 0.3406,  0.0350,  0.2793, -0.4562,  0.6643],\n",
      "         [-0.3303,  2.1596,  1.2740,  0.6125, -0.8145],\n",
      "         [ 1.3573, -0.7365,  0.5432,  1.0916, -0.1357]]],\n",
      "       grad_fn=<EmbeddingBackward0>)\n",
      "\n",
      "emb_layer.shape:  torch.Size([2, 3, 5])\n"
     ]
    }
   ],
   "source": [
    "##\n",
    "vocab_size=100\n",
    "emd_dime=5\n",
    "\n",
    "emd_layer=torch.nn.Embedding(num_embeddings=vocab_size,embedding_dim=emd_dime)\n",
    "\n",
    "embedded_inp_shape=emd_layer(input_example)\n",
    "\n",
    "print('emd_layer:  ',embedded_inp_shape)\n",
    "print(\"\\nemb_layer.shape: \",embedded_inp_shape.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 5])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedded_inp_shape.mean(dim=1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
