{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/akash/anaconda3/envs/vision/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "from torch.optim import SGD,lr_scheduler\n",
    "from torch.nn import Sequential, Linear, Embedding\n",
    "from torch.utils.data import DataLoader\n",
    "import torchtext\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##other library\n",
    "import numpy as np\n",
    "import datasets\n",
    "import os \n",
    "import tqdm\n",
    "import collections\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device:  cuda\n"
     ]
    }
   ],
   "source": [
    "device=('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('device: ',device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed=1234\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic=True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data,test_data=datasets.load_dataset('imdb',split=['train','test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label'],\n",
       "    num_rows: 25000\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I rented I AM CURIOUS-YELLOW from my video store because of all the controversy that surrounded it when it was first released in 1967. I also heard that at first it was seized by U.S. customs if it ever tried to enter this country, therefore being a fan of films considered \"controversial\" I really had to see this for myself.<br /><br />The plot is centered around a young Swedish drama student named Lena who wants to learn everything she can about life. In particular she wants to focus her attentions to making some sort of documentary on what the average Swede thought about certain political issues such as the Vietnam War and race issues in the United States. In between asking politicians and ordinary denizens of Stockholm about their opinions on politics, she has sex with her drama teacher, classmates, and married men.<br /><br />What kills me about I AM CURIOUS-YELLOW is that 40 years ago, this was considered pornographic. Really, the sex and nudity scenes are few and far between, even then it\\'s not shot like some cheaply made porno. While my countrymen mind find it shocking, in reality sex and nudity are a major staple in Swedish cinema. Even Ingmar Bergman, arguably their answer to good old boy John Ford, had sex scenes in his films.<br /><br />I do commend the filmmakers for the fact that any sex shown in the film is shown for artistic purposes rather than just to shock people and make money to be shown in pornographic theaters in America. I AM CURIOUS-YELLOW is a good film for anyone wanting to study the meat and potatoes (no pun intended) of Swedish cinema. But really, this film doesn\\'t have much of a plot.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['text'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': Value(dtype='string', id=None),\n",
       " 'label': ClassLabel(names=['neg', 'pos'], id=None)}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.features ## have two labels neg and pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I rented I AM CURIOUS-YELLOW from my video store because of all the controversy that surrounded it w\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(train_data[0]['text'][:100])\n",
    "print(train_data[0]['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['text', 'label'])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0].keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenization\n",
    "\n",
    "ML models trains on numerical value only. So we will convert each string to int value using tokenizer. In order to do so first we need to separate `str` to individual tokens, and laters converts them into number. \n",
    "\n",
    "- using,`tokenizer` we will convert strings into number of tokens first. \n",
    "- later, we will use look_up_table  to convert each tokens(in str) to int. We do this by creating a vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer=torchtext.data.utils.get_tokenizer('basic_english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_text='Hello, I am from Nepal!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hello', ',', 'i', 'am', 'from', 'nepal', '!']\n"
     ]
    }
   ],
   "source": [
    "sample_tokenized_text=tokenizer(sample_text)\n",
    "print(sample_tokenized_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## sometimes the str might contain to many unnecessary tokens; so we will take max_length and define by function\n",
    "\n",
    "# def tokenize_example(example,tokenizer,max_length):\n",
    "#     tokens=tokenizer(example['text'])[:max_length]\n",
    "#     return {'tokens':tokens}\n",
    "\n",
    "# ## we return dictionary coz train_data are in the same format.  When use with map fucntion later we will see new tokens (with key) is appended in train_data format\n",
    "# max_length=256\n",
    "\n",
    "# train_data=train_data.map(tokenize_example,\n",
    "#                           fn_kwargs={'tokenizer':tokenizer,\n",
    "#                                      'max_length':max_length})\n",
    "\n",
    "# test_data=test_data.map(tokenize_example,\n",
    "#                           fn_kwargs={'tokenizer':tokenizer,\n",
    "#                                      'max_length':max_length})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "## sometimes the str might contain to many unnecessary tokens; so we will take max_length and define by function\n",
    "\n",
    "def tokenize_example(example,max_length):\n",
    "    tokens=tokenizer(example['text'])[:max_length]\n",
    "    return {'tokens':tokens}\n",
    "\n",
    "## we return dictionary coz train_data are in the same format.  When use with map fucntion later we will see new tokens (with key) is appended in train_data format\n",
    "max_length=256\n",
    "\n",
    "train_data=train_data.map(tokenize_example,\n",
    "                          fn_kwargs={\n",
    "                                     'max_length':max_length})\n",
    "\n",
    "test_data=test_data.map(tokenize_example,\n",
    "                          fn_kwargs={\n",
    "                                     'max_length':max_length})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I rented I AM CURIOUS-YELLOW from my video store because of all the controversy that surrounded it w'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0]['text'][:100] ##we will convert this to tokens using the above fucntion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92\n",
      "99\n",
      "57\n",
      "86\n",
      "64\n",
      "61\n",
      "56\n",
      "83\n",
      "83\n",
      "58\n",
      "86\n",
      "82\n",
      "69\n",
      "95\n",
      "95\n",
      "50\n",
      "99\n",
      "84\n",
      "71\n",
      "64\n",
      "68\n",
      "61\n",
      "93\n",
      "92\n",
      "67\n",
      "41\n",
      "73\n",
      "80\n",
      "75\n",
      "74\n",
      "28\n",
      "96\n",
      "47\n",
      "89\n",
      "16\n",
      "73\n",
      "95\n",
      "40\n",
      "79\n",
      "87\n",
      "49\n",
      "93\n",
      "74\n",
      "68\n",
      "56\n",
      "72\n",
      "95\n",
      "55\n",
      "57\n",
      "68\n",
      "89\n",
      "94\n",
      "76\n",
      "67\n",
      "54\n",
      "57\n",
      "94\n",
      "42\n",
      "46\n",
      "81\n",
      "44\n",
      "84\n",
      "85\n",
      "18\n",
      "91\n",
      "71\n",
      "99\n",
      "72\n",
      "37\n",
      "80\n",
      "94\n",
      "79\n",
      "68\n",
      "93\n",
      "65\n",
      "83\n",
      "42\n",
      "61\n",
      "67\n",
      "99\n",
      "57\n",
      "67\n",
      "60\n",
      "93\n",
      "71\n",
      "51\n",
      "63\n",
      "64\n",
      "93\n",
      "76\n",
      "87\n",
      "89\n",
      "61\n",
      "63\n",
      "90\n",
      "65\n",
      "65\n",
      "77\n",
      "96\n",
      "83\n",
      "86\n",
      "55\n",
      "46\n",
      "43\n",
      "96\n",
      "73\n",
      "68\n",
      "80\n",
      "99\n",
      "77\n",
      "66\n",
      "83\n",
      "70\n",
      "60\n",
      "62\n",
      "83\n",
      "63\n",
      "95\n",
      "77\n",
      "62\n",
      "70\n",
      "69\n",
      "83\n",
      "90\n",
      "86\n",
      "69\n",
      "96\n",
      "97\n",
      "44\n",
      "96\n",
      "53\n",
      "97\n",
      "97\n",
      "53\n",
      "79\n",
      "72\n",
      "92\n",
      "48\n",
      "86\n",
      "32\n",
      "80\n",
      "69\n",
      "51\n",
      "57\n",
      "97\n",
      "98\n",
      "63\n",
      "82\n",
      "68\n",
      "59\n",
      "66\n",
      "90\n",
      "24\n",
      "77\n",
      "79\n",
      "57\n",
      "74\n",
      "70\n",
      "68\n",
      "49\n",
      "97\n",
      "92\n",
      "75\n",
      "73\n",
      "47\n",
      "82\n",
      "74\n",
      "55\n",
      "98\n",
      "77\n",
      "88\n",
      "76\n",
      "91\n",
      "67\n",
      "98\n",
      "91\n",
      "59\n",
      "54\n",
      "87\n",
      "51\n",
      "79\n",
      "75\n",
      "85\n",
      "86\n",
      "79\n",
      "62\n",
      "67\n",
      "89\n",
      "91\n",
      "78\n",
      "89\n",
      "39\n",
      "71\n",
      "87\n",
      "88\n",
      "75\n",
      "68\n",
      "51\n",
      "82\n",
      "75\n",
      "72\n",
      "60\n",
      "77\n",
      "64\n",
      "39\n",
      "65\n",
      "84\n",
      "78\n",
      "46\n",
      "13\n",
      "75\n",
      "55\n",
      "95\n",
      "74\n",
      "60\n",
      "93\n",
      "89\n",
      "58\n",
      "55\n",
      "96\n",
      "88\n",
      "50\n",
      "32\n",
      "94\n",
      "98\n",
      "93\n",
      "57\n",
      "77\n",
      "75\n",
      "85\n",
      "52\n",
      "71\n",
      "86\n",
      "49\n",
      "84\n",
      "69\n",
      "96\n",
      "58\n",
      "72\n",
      "98\n",
      "66\n",
      "64\n",
      "59\n",
      "62\n",
      "70\n",
      "91\n",
      "55\n",
      "90\n",
      "94\n",
      "97\n",
      "74\n",
      "59\n",
      "65\n",
      "76\n",
      "79\n",
      "25\n",
      "83\n",
      "60\n",
      "55\n",
      "96\n",
      "55\n",
      "78\n",
      "77\n",
      "88\n",
      "57\n",
      "42\n",
      "86\n",
      "87\n",
      "69\n",
      "68\n",
      "64\n",
      "90\n",
      "98\n",
      "53\n",
      "43\n",
      "66\n",
      "92\n",
      "98\n",
      "42\n",
      "60\n",
      "71\n",
      "69\n",
      "45\n",
      "83\n",
      "83\n",
      "64\n",
      "95\n",
      "44\n",
      "94\n",
      "70\n",
      "55\n",
      "56\n",
      "81\n",
      "65\n",
      "57\n",
      "76\n",
      "78\n",
      "72\n",
      "63\n",
      "66\n",
      "73\n",
      "84\n",
      "38\n",
      "77\n",
      "56\n",
      "89\n",
      "99\n",
      "97\n",
      "57\n",
      "39\n",
      "63\n",
      "68\n",
      "76\n",
      "63\n",
      "98\n",
      "44\n",
      "37\n",
      "79\n",
      "66\n",
      "66\n",
      "83\n",
      "98\n",
      "49\n",
      "72\n",
      "91\n",
      "60\n",
      "54\n",
      "78\n",
      "38\n",
      "95\n",
      "57\n",
      "51\n",
      "86\n",
      "84\n",
      "73\n",
      "94\n",
      "64\n",
      "72\n",
      "94\n",
      "49\n",
      "69\n",
      "42\n",
      "68\n",
      "91\n",
      "96\n",
      "50\n",
      "44\n",
      "91\n",
      "44\n",
      "64\n",
      "84\n",
      "70\n",
      "77\n",
      "54\n",
      "83\n",
      "80\n",
      "46\n",
      "94\n",
      "70\n",
      "51\n",
      "71\n",
      "38\n",
      "49\n",
      "90\n",
      "91\n",
      "60\n",
      "69\n",
      "96\n",
      "99\n",
      "65\n",
      "56\n",
      "93\n",
      "78\n",
      "76\n",
      "81\n",
      "53\n",
      "86\n",
      "47\n",
      "87\n",
      "57\n",
      "96\n",
      "95\n",
      "78\n",
      "82\n",
      "47\n",
      "90\n",
      "90\n",
      "92\n",
      "84\n",
      "77\n",
      "82\n",
      "65\n",
      "44\n",
      "98\n",
      "79\n",
      "93\n",
      "95\n",
      "97\n",
      "65\n",
      "74\n",
      "32\n",
      "61\n",
      "56\n",
      "99\n",
      "51\n",
      "80\n",
      "73\n",
      "34\n",
      "92\n",
      "20\n",
      "91\n",
      "93\n",
      "63\n",
      "66\n",
      "59\n",
      "49\n",
      "72\n",
      "67\n",
      "71\n",
      "69\n",
      "75\n",
      "71\n",
      "53\n",
      "58\n",
      "40\n",
      "38\n",
      "99\n",
      "60\n",
      "44\n",
      "60\n",
      "54\n",
      "87\n",
      "83\n",
      "69\n",
      "45\n",
      "76\n",
      "62\n",
      "88\n",
      "90\n",
      "89\n",
      "67\n",
      "88\n",
      "60\n",
      "89\n",
      "92\n",
      "92\n",
      "97\n",
      "67\n",
      "94\n",
      "75\n",
      "98\n",
      "84\n",
      "84\n",
      "68\n",
      "68\n",
      "93\n",
      "63\n",
      "53\n",
      "70\n",
      "64\n",
      "90\n",
      "77\n",
      "86\n",
      "97\n",
      "76\n",
      "75\n",
      "58\n",
      "40\n",
      "56\n",
      "78\n",
      "81\n",
      "76\n",
      "58\n",
      "68\n",
      "62\n",
      "79\n",
      "60\n",
      "91\n",
      "70\n",
      "49\n",
      "62\n",
      "91\n",
      "69\n",
      "79\n",
      "48\n",
      "66\n",
      "56\n",
      "55\n",
      "55\n",
      "72\n",
      "79\n",
      "71\n",
      "46\n",
      "81\n",
      "66\n",
      "57\n",
      "52\n",
      "62\n",
      "74\n",
      "92\n",
      "95\n",
      "65\n",
      "77\n",
      "43\n",
      "89\n",
      "87\n",
      "85\n",
      "76\n",
      "88\n",
      "79\n",
      "98\n",
      "64\n",
      "50\n",
      "72\n",
      "68\n",
      "68\n",
      "75\n",
      "68\n",
      "97\n",
      "69\n",
      "69\n",
      "93\n",
      "84\n",
      "37\n",
      "78\n",
      "76\n",
      "66\n",
      "82\n",
      "56\n",
      "81\n",
      "53\n",
      "87\n",
      "88\n",
      "57\n",
      "85\n",
      "96\n",
      "56\n",
      "99\n",
      "58\n",
      "88\n",
      "79\n",
      "55\n",
      "82\n",
      "56\n",
      "84\n",
      "66\n",
      "51\n",
      "89\n",
      "85\n",
      "87\n",
      "52\n",
      "87\n",
      "70\n",
      "84\n",
      "59\n",
      "78\n",
      "25\n",
      "50\n",
      "76\n",
      "71\n",
      "62\n",
      "72\n",
      "78\n",
      "49\n",
      "98\n",
      "82\n",
      "78\n",
      "99\n",
      "84\n",
      "65\n",
      "54\n",
      "83\n",
      "54\n",
      "75\n",
      "57\n",
      "86\n",
      "77\n",
      "52\n",
      "78\n",
      "91\n",
      "71\n",
      "58\n",
      "81\n",
      "44\n",
      "32\n",
      "83\n",
      "63\n",
      "83\n",
      "92\n",
      "69\n",
      "87\n",
      "54\n",
      "92\n",
      "99\n",
      "81\n",
      "76\n",
      "61\n",
      "96\n",
      "83\n",
      "70\n",
      "97\n",
      "97\n",
      "65\n",
      "52\n",
      "52\n",
      "97\n",
      "77\n",
      "59\n",
      "75\n",
      "89\n",
      "90\n",
      "64\n",
      "90\n",
      "88\n",
      "70\n",
      "73\n",
      "84\n",
      "86\n",
      "89\n",
      "99\n",
      "49\n",
      "69\n",
      "82\n",
      "86\n",
      "67\n",
      "92\n",
      "72\n",
      "92\n",
      "88\n",
      "58\n",
      "58\n",
      "56\n",
      "45\n",
      "44\n",
      "37\n",
      "68\n",
      "83\n",
      "97\n",
      "83\n",
      "51\n",
      "95\n",
      "81\n",
      "86\n",
      "67\n",
      "76\n",
      "59\n",
      "69\n",
      "81\n",
      "69\n",
      "97\n",
      "75\n",
      "55\n",
      "48\n",
      "86\n",
      "63\n",
      "91\n",
      "57\n",
      "72\n",
      "95\n",
      "66\n",
      "92\n",
      "96\n",
      "59\n",
      "97\n",
      "79\n",
      "86\n",
      "87\n",
      "78\n",
      "68\n",
      "71\n",
      "92\n",
      "98\n",
      "84\n",
      "60\n",
      "40\n",
      "86\n",
      "86\n",
      "59\n",
      "56\n",
      "62\n",
      "85\n",
      "80\n",
      "68\n",
      "90\n",
      "71\n",
      "58\n",
      "26\n",
      "99\n",
      "37\n",
      "55\n",
      "74\n",
      "81\n",
      "81\n",
      "96\n",
      "77\n",
      "85\n",
      "61\n",
      "64\n",
      "80\n",
      "74\n",
      "86\n",
      "59\n",
      "71\n",
      "91\n",
      "79\n",
      "88\n",
      "91\n",
      "91\n",
      "51\n",
      "49\n",
      "95\n",
      "58\n",
      "42\n",
      "45\n",
      "52\n",
      "44\n",
      "58\n",
      "88\n",
      "62\n",
      "60\n",
      "66\n",
      "94\n",
      "70\n",
      "84\n",
      "61\n",
      "72\n",
      "94\n",
      "61\n",
      "77\n",
      "69\n",
      "52\n",
      "78\n",
      "90\n",
      "66\n",
      "48\n",
      "69\n",
      "93\n",
      "86\n",
      "67\n",
      "93\n",
      "69\n",
      "81\n",
      "94\n",
      "96\n",
      "89\n",
      "90\n",
      "69\n",
      "81\n",
      "38\n",
      "94\n",
      "56\n",
      "71\n",
      "50\n",
      "85\n",
      "82\n",
      "78\n",
      "47\n",
      "71\n",
      "62\n",
      "61\n",
      "62\n",
      "23\n",
      "97\n",
      "76\n",
      "74\n",
      "58\n",
      "99\n",
      "56\n",
      "77\n",
      "66\n",
      "61\n",
      "61\n",
      "54\n",
      "75\n",
      "50\n",
      "75\n",
      "82\n",
      "92\n",
      "73\n",
      "54\n",
      "52\n",
      "86\n",
      "74\n",
      "84\n",
      "84\n",
      "53\n",
      "68\n",
      "46\n",
      "74\n",
      "89\n",
      "58\n",
      "62\n",
      "58\n",
      "59\n",
      "66\n",
      "37\n",
      "47\n",
      "62\n",
      "96\n",
      "66\n",
      "54\n",
      "63\n",
      "56\n",
      "84\n",
      "59\n",
      "91\n",
      "52\n",
      "69\n",
      "98\n",
      "67\n",
      "66\n",
      "87\n",
      "94\n",
      "48\n",
      "58\n",
      "53\n",
      "75\n",
      "59\n",
      "63\n",
      "98\n",
      "98\n",
      "65\n",
      "81\n",
      "73\n",
      "84\n",
      "93\n",
      "56\n",
      "99\n",
      "67\n",
      "52\n",
      "56\n",
      "53\n",
      "69\n",
      "92\n",
      "81\n",
      "56\n",
      "69\n",
      "11\n",
      "72\n",
      "82\n",
      "89\n",
      "87\n",
      "98\n",
      "90\n",
      "80\n",
      "78\n",
      "97\n",
      "52\n",
      "56\n",
      "78\n",
      "70\n",
      "67\n",
      "86\n",
      "90\n",
      "86\n",
      "28\n",
      "57\n",
      "67\n",
      "97\n",
      "89\n",
      "60\n",
      "94\n",
      "83\n",
      "93\n",
      "69\n",
      "58\n",
      "82\n",
      "58\n",
      "69\n",
      "83\n",
      "96\n",
      "99\n",
      "49\n",
      "84\n",
      "67\n",
      "50\n",
      "86\n",
      "61\n",
      "92\n",
      "79\n",
      "87\n",
      "91\n",
      "71\n",
      "83\n",
      "60\n",
      "56\n",
      "94\n",
      "89\n",
      "44\n",
      "76\n",
      "65\n",
      "59\n",
      "86\n",
      "92\n",
      "52\n",
      "93\n",
      "73\n",
      "53\n",
      "70\n",
      "73\n",
      "96\n",
      "66\n",
      "84\n",
      "49\n",
      "84\n",
      "92\n",
      "88\n",
      "47\n",
      "69\n",
      "65\n",
      "45\n",
      "50\n",
      "73\n",
      "91\n",
      "44\n",
      "29\n",
      "94\n",
      "50\n",
      "80\n",
      "70\n",
      "78\n",
      "73\n",
      "53\n",
      "81\n",
      "67\n",
      "65\n",
      "47\n",
      "57\n",
      "72\n",
      "76\n",
      "92\n",
      "13\n",
      "92\n",
      "76\n",
      "43\n",
      "99\n",
      "75\n",
      "96\n",
      "98\n",
      "89\n",
      "83\n",
      "62\n",
      "90\n",
      "57\n",
      "65\n",
      "85\n",
      "75\n",
      "75\n",
      "36\n",
      "41\n",
      "90\n",
      "78\n",
      "32\n",
      "85\n",
      "74\n",
      "61\n",
      "89\n",
      "81\n",
      "60\n",
      "79\n",
      "88\n",
      "99\n",
      "66\n",
      "97\n",
      "75\n",
      "63\n",
      "47\n",
      "54\n",
      "72\n",
      "98\n",
      "46\n",
      "73\n",
      "72\n",
      "50\n",
      "70\n",
      "46\n",
      "47\n",
      "88\n",
      "98\n",
      "58\n",
      "48\n",
      "50\n",
      "61\n",
      "63\n",
      "55\n",
      "94\n",
      "31\n",
      "97\n",
      "80\n",
      "81\n",
      "47\n",
      "53\n",
      "91\n",
      "75\n",
      "86\n",
      "92\n",
      "76\n",
      "79\n",
      "84\n",
      "68\n",
      "80\n",
      "83\n",
      "70\n",
      "35\n",
      "76\n",
      "90\n",
      "92\n",
      "77\n",
      "78\n",
      "71\n",
      "87\n",
      "56\n",
      "42\n",
      "53\n",
      "52\n",
      "68\n",
      "72\n",
      "88\n",
      "88\n",
      "73\n",
      "62\n",
      "61\n",
      "74\n",
      "57\n",
      "81\n",
      "92\n",
      "79\n",
      "47\n",
      "75\n",
      "93\n",
      "93\n",
      "68\n",
      "95\n",
      "94\n",
      "94\n",
      "97\n",
      "80\n",
      "72\n",
      "40\n",
      "93\n",
      "59\n",
      "86\n",
      "72\n",
      "94\n",
      "67\n",
      "97\n",
      "90\n",
      "94\n",
      "77\n",
      "63\n",
      "51\n",
      "63\n",
      "89\n",
      "49\n",
      "60\n",
      "98\n",
      "87\n",
      "87\n",
      "87\n",
      "48\n",
      "73\n",
      "65\n",
      "83\n",
      "54\n",
      "61\n",
      "94\n",
      "63\n",
      "88\n",
      "59\n",
      "90\n",
      "85\n",
      "41\n",
      "48\n",
      "76\n",
      "95\n",
      "70\n",
      "85\n",
      "61\n",
      "68\n",
      "82\n",
      "78\n",
      "56\n",
      "69\n",
      "95\n",
      "47\n",
      "67\n",
      "74\n",
      "71\n",
      "85\n",
      "74\n",
      "60\n",
      "45\n",
      "28\n",
      "85\n",
      "97\n",
      "68\n",
      "86\n",
      "68\n",
      "71\n",
      "94\n",
      "36\n",
      "89\n",
      "98\n",
      "56\n",
      "67\n",
      "93\n",
      "55\n",
      "45\n",
      "83\n",
      "79\n",
      "64\n",
      "89\n",
      "62\n",
      "98\n",
      "96\n",
      "70\n",
      "52\n",
      "91\n",
      "75\n",
      "89\n",
      "72\n",
      "61\n",
      "99\n",
      "99\n",
      "66\n",
      "81\n",
      "73\n",
      "73\n",
      "94\n",
      "93\n",
      "98\n",
      "74\n",
      "97\n",
      "29\n",
      "31\n",
      "99\n",
      "65\n",
      "65\n",
      "95\n",
      "96\n",
      "92\n",
      "92\n",
      "72\n",
      "74\n",
      "96\n",
      "66\n",
      "48\n",
      "48\n",
      "50\n",
      "29\n",
      "66\n",
      "80\n",
      "55\n",
      "96\n",
      "95\n",
      "70\n",
      "56\n",
      "87\n",
      "60\n",
      "64\n",
      "65\n",
      "97\n",
      "95\n",
      "63\n",
      "77\n",
      "65\n",
      "85\n",
      "94\n",
      "82\n",
      "64\n",
      "71\n",
      "96\n",
      "54\n",
      "52\n",
      "94\n",
      "70\n",
      "86\n",
      "76\n",
      "95\n",
      "72\n",
      "49\n",
      "61\n",
      "42\n",
      "35\n",
      "72\n",
      "96\n",
      "72\n",
      "80\n",
      "79\n",
      "99\n",
      "65\n",
      "49\n",
      "33\n",
      "86\n",
      "92\n",
      "77\n",
      "72\n",
      "81\n",
      "53\n",
      "68\n",
      "25\n",
      "47\n",
      "36\n",
      "50\n",
      "68\n",
      "79\n",
      "71\n",
      "64\n",
      "65\n",
      "93\n",
      "61\n",
      "80\n",
      "38\n",
      "47\n",
      "98\n",
      "40\n",
      "95\n",
      "62\n",
      "55\n",
      "89\n",
      "20\n",
      "95\n",
      "79\n",
      "38\n",
      "56\n",
      "48\n",
      "51\n",
      "56\n",
      "80\n",
      "90\n",
      "90\n",
      "73\n",
      "55\n",
      "99\n",
      "64\n",
      "88\n",
      "62\n",
      "89\n",
      "67\n",
      "69\n",
      "74\n",
      "67\n",
      "88\n",
      "91\n",
      "77\n",
      "72\n",
      "46\n",
      "65\n",
      "88\n",
      "38\n",
      "61\n",
      "51\n",
      "63\n",
      "68\n",
      "88\n",
      "51\n",
      "71\n",
      "76\n",
      "79\n",
      "86\n",
      "67\n",
      "71\n",
      "83\n",
      "77\n",
      "70\n",
      "79\n",
      "57\n",
      "73\n",
      "58\n",
      "68\n",
      "58\n",
      "88\n",
      "80\n",
      "63\n",
      "61\n",
      "96\n",
      "59\n",
      "91\n",
      "62\n",
      "72\n",
      "58\n",
      "84\n",
      "79\n",
      "48\n",
      "82\n",
      "51\n",
      "42\n",
      "85\n",
      "55\n",
      "54\n",
      "98\n",
      "43\n",
      "91\n",
      "47\n",
      "88\n",
      "82\n",
      "80\n",
      "62\n",
      "81\n",
      "65\n",
      "45\n",
      "85\n",
      "65\n",
      "22\n",
      "81\n",
      "87\n",
      "91\n",
      "48\n",
      "67\n",
      "83\n",
      "54\n",
      "78\n",
      "74\n",
      "79\n",
      "73\n",
      "81\n",
      "61\n",
      "35\n",
      "53\n",
      "47\n",
      "94\n",
      "62\n",
      "38\n",
      "79\n",
      "80\n",
      "70\n",
      "79\n",
      "90\n",
      "62\n",
      "75\n",
      "70\n",
      "88\n",
      "88\n",
      "47\n",
      "99\n",
      "81\n",
      "56\n",
      "84\n",
      "51\n",
      "86\n",
      "76\n",
      "73\n",
      "51\n",
      "56\n",
      "86\n",
      "83\n",
      "92\n",
      "79\n",
      "70\n",
      "51\n",
      "53\n",
      "55\n",
      "80\n",
      "77\n",
      "86\n",
      "60\n",
      "49\n",
      "86\n",
      "99\n",
      "56\n",
      "81\n",
      "76\n",
      "41\n",
      "56\n",
      "68\n",
      "60\n",
      "49\n",
      "64\n",
      "62\n",
      "75\n",
      "93\n",
      "63\n",
      "92\n",
      "65\n",
      "42\n",
      "73\n",
      "81\n",
      "48\n",
      "63\n",
      "60\n",
      "32\n",
      "36\n",
      "47\n",
      "90\n",
      "27\n",
      "99\n",
      "95\n",
      "52\n",
      "42\n",
      "71\n",
      "99\n",
      "69\n",
      "55\n",
      "50\n",
      "24\n",
      "54\n",
      "50\n",
      "71\n",
      "99\n",
      "88\n",
      "68\n",
      "95\n",
      "46\n",
      "42\n",
      "55\n",
      "65\n",
      "47\n",
      "47\n",
      "65\n",
      "46\n",
      "64\n",
      "59\n",
      "56\n",
      "68\n",
      "65\n",
      "48\n",
      "54\n",
      "63\n",
      "85\n",
      "95\n",
      "64\n",
      "48\n",
      "71\n",
      "60\n",
      "88\n",
      "82\n",
      "75\n",
      "78\n",
      "70\n",
      "82\n",
      "61\n",
      "58\n",
      "63\n",
      "65\n",
      "81\n",
      "84\n",
      "87\n",
      "84\n",
      "83\n",
      "92\n",
      "52\n",
      "51\n",
      "97\n",
      "71\n",
      "73\n",
      "63\n",
      "14\n",
      "75\n",
      "62\n",
      "78\n",
      "74\n",
      "53\n",
      "70\n",
      "92\n",
      "85\n",
      "76\n",
      "58\n",
      "73\n",
      "89\n",
      "74\n",
      "48\n",
      "57\n",
      "86\n",
      "86\n",
      "57\n",
      "93\n",
      "80\n",
      "93\n",
      "90\n",
      "69\n",
      "85\n",
      "69\n",
      "94\n",
      "49\n",
      "75\n",
      "54\n",
      "96\n",
      "98\n",
      "89\n",
      "69\n",
      "61\n",
      "56\n",
      "75\n",
      "62\n",
      "61\n",
      "87\n",
      "76\n",
      "84\n",
      "72\n",
      "47\n",
      "51\n",
      "87\n",
      "87\n",
      "69\n",
      "46\n",
      "83\n",
      "84\n",
      "79\n",
      "50\n",
      "74\n",
      "82\n",
      "82\n",
      "93\n",
      "48\n",
      "60\n",
      "87\n",
      "41\n",
      "89\n",
      "65\n",
      "68\n",
      "65\n",
      "89\n",
      "88\n",
      "83\n",
      "60\n",
      "48\n",
      "70\n",
      "48\n",
      "37\n",
      "89\n",
      "92\n",
      "83\n",
      "81\n",
      "62\n",
      "93\n",
      "48\n",
      "57\n",
      "54\n",
      "60\n",
      "56\n",
      "75\n",
      "82\n",
      "42\n",
      "96\n",
      "68\n",
      "81\n",
      "84\n",
      "87\n",
      "48\n",
      "73\n",
      "80\n",
      "44\n",
      "43\n",
      "48\n",
      "83\n",
      "87\n",
      "93\n",
      "84\n",
      "62\n",
      "64\n",
      "54\n",
      "71\n",
      "54\n",
      "86\n",
      "76\n",
      "99\n",
      "69\n",
      "90\n",
      "87\n",
      "84\n",
      "81\n",
      "71\n",
      "94\n",
      "53\n",
      "71\n",
      "74\n",
      "73\n",
      "61\n",
      "47\n",
      "54\n",
      "68\n",
      "85\n",
      "79\n",
      "67\n",
      "47\n",
      "77\n",
      "61\n",
      "74\n",
      "59\n",
      "62\n",
      "91\n",
      "79\n",
      "91\n",
      "49\n",
      "86\n",
      "70\n",
      "87\n",
      "84\n",
      "42\n",
      "39\n",
      "89\n",
      "96\n",
      "47\n",
      "51\n",
      "88\n",
      "71\n",
      "88\n",
      "99\n",
      "66\n",
      "46\n",
      "86\n",
      "46\n",
      "64\n",
      "72\n",
      "91\n",
      "65\n",
      "69\n",
      "92\n",
      "58\n",
      "56\n",
      "45\n",
      "54\n",
      "90\n",
      "56\n",
      "81\n",
      "69\n",
      "67\n",
      "93\n",
      "69\n",
      "71\n",
      "66\n",
      "71\n",
      "91\n",
      "46\n",
      "61\n",
      "66\n",
      "63\n",
      "98\n",
      "80\n",
      "80\n",
      "44\n",
      "46\n",
      "47\n",
      "71\n",
      "81\n",
      "83\n",
      "59\n",
      "87\n",
      "65\n",
      "45\n",
      "51\n",
      "59\n",
      "51\n",
      "94\n",
      "66\n",
      "64\n",
      "80\n",
      "82\n",
      "47\n",
      "71\n",
      "62\n",
      "70\n",
      "98\n",
      "74\n",
      "57\n",
      "75\n",
      "68\n",
      "77\n",
      "58\n",
      "63\n",
      "48\n",
      "50\n",
      "98\n",
      "88\n",
      "93\n",
      "43\n",
      "81\n",
      "84\n",
      "78\n",
      "60\n",
      "71\n",
      "72\n",
      "98\n",
      "77\n",
      "57\n",
      "61\n",
      "65\n",
      "49\n",
      "51\n",
      "82\n",
      "88\n",
      "58\n",
      "64\n",
      "51\n",
      "83\n",
      "73\n",
      "53\n",
      "80\n",
      "61\n",
      "70\n",
      "80\n",
      "44\n",
      "67\n",
      "98\n",
      "71\n",
      "85\n",
      "45\n",
      "78\n",
      "66\n",
      "77\n",
      "61\n",
      "91\n",
      "99\n",
      "93\n",
      "68\n",
      "53\n",
      "70\n",
      "59\n",
      "63\n",
      "72\n",
      "72\n",
      "86\n",
      "74\n",
      "76\n",
      "79\n",
      "46\n",
      "50\n",
      "58\n",
      "72\n",
      "46\n",
      "92\n",
      "51\n",
      "45\n",
      "67\n",
      "61\n",
      "60\n",
      "70\n",
      "74\n",
      "87\n",
      "90\n",
      "78\n",
      "92\n",
      "78\n",
      "88\n",
      "90\n",
      "99\n",
      "53\n",
      "39\n",
      "71\n",
      "48\n",
      "69\n",
      "71\n",
      "92\n",
      "75\n",
      "99\n",
      "92\n",
      "95\n",
      "71\n",
      "40\n",
      "53\n",
      "93\n",
      "55\n",
      "42\n",
      "63\n",
      "92\n",
      "70\n",
      "80\n",
      "61\n",
      "70\n",
      "92\n",
      "83\n",
      "74\n",
      "95\n",
      "87\n",
      "64\n",
      "96\n",
      "58\n",
      "92\n",
      "55\n",
      "92\n",
      "87\n",
      "53\n",
      "64\n",
      "93\n",
      "87\n",
      "68\n",
      "95\n",
      "71\n",
      "54\n",
      "67\n",
      "66\n",
      "96\n",
      "71\n",
      "89\n",
      "30\n",
      "81\n",
      "89\n",
      "84\n",
      "56\n",
      "50\n",
      "56\n",
      "69\n",
      "69\n",
      "64\n",
      "69\n",
      "99\n",
      "64\n",
      "60\n",
      "96\n",
      "68\n",
      "79\n",
      "85\n",
      "88\n",
      "68\n",
      "83\n",
      "86\n",
      "95\n",
      "56\n",
      "56\n",
      "36\n",
      "65\n",
      "88\n",
      "89\n",
      "64\n",
      "55\n",
      "72\n",
      "87\n",
      "75\n",
      "97\n",
      "84\n",
      "93\n",
      "44\n",
      "46\n",
      "97\n",
      "88\n",
      "97\n",
      "60\n",
      "86\n",
      "60\n",
      "46\n",
      "66\n",
      "57\n",
      "64\n",
      "69\n",
      "92\n",
      "87\n",
      "85\n",
      "99\n",
      "85\n",
      "85\n",
      "74\n",
      "92\n",
      "76\n",
      "27\n",
      "58\n",
      "36\n",
      "65\n",
      "68\n",
      "63\n",
      "84\n",
      "92\n",
      "49\n",
      "69\n",
      "38\n",
      "55\n",
      "55\n",
      "75\n",
      "67\n",
      "66\n",
      "67\n",
      "36\n",
      "81\n",
      "50\n",
      "49\n",
      "84\n",
      "87\n",
      "72\n",
      "63\n",
      "77\n",
      "86\n",
      "72\n",
      "89\n",
      "67\n",
      "50\n",
      "57\n",
      "66\n",
      "61\n",
      "69\n",
      "79\n",
      "53\n",
      "83\n",
      "69\n",
      "90\n",
      "99\n",
      "56\n",
      "90\n",
      "53\n",
      "53\n",
      "50\n",
      "64\n",
      "58\n",
      "77\n",
      "49\n",
      "91\n",
      "85\n",
      "72\n",
      "63\n",
      "88\n",
      "43\n",
      "53\n",
      "39\n",
      "79\n",
      "56\n",
      "65\n",
      "48\n",
      "77\n",
      "74\n",
      "86\n",
      "96\n",
      "35\n",
      "96\n",
      "98\n",
      "99\n",
      "92\n",
      "40\n",
      "48\n",
      "61\n",
      "60\n",
      "73\n",
      "65\n",
      "51\n",
      "82\n",
      "67\n",
      "78\n",
      "41\n",
      "74\n",
      "59\n",
      "67\n",
      "56\n",
      "98\n",
      "98\n",
      "51\n",
      "67\n",
      "96\n",
      "67\n",
      "43\n",
      "91\n",
      "57\n",
      "90\n",
      "64\n",
      "84\n",
      "72\n",
      "83\n",
      "77\n",
      "62\n",
      "65\n",
      "66\n",
      "67\n",
      "97\n",
      "96\n",
      "42\n",
      "89\n",
      "83\n",
      "83\n",
      "53\n",
      "82\n",
      "97\n",
      "65\n",
      "69\n",
      "61\n",
      "52\n",
      "62\n",
      "84\n",
      "88\n",
      "52\n",
      "56\n",
      "92\n",
      "70\n",
      "77\n",
      "63\n",
      "68\n",
      "64\n",
      "87\n",
      "62\n",
      "61\n",
      "83\n",
      "47\n",
      "62\n",
      "99\n",
      "62\n",
      "62\n",
      "86\n",
      "91\n",
      "95\n",
      "95\n",
      "48\n",
      "91\n",
      "35\n",
      "57\n",
      "83\n",
      "61\n",
      "81\n",
      "76\n",
      "65\n",
      "44\n",
      "89\n",
      "44\n",
      "90\n",
      "76\n",
      "70\n",
      "45\n",
      "98\n",
      "75\n",
      "82\n",
      "85\n",
      "55\n",
      "94\n",
      "41\n",
      "97\n",
      "83\n",
      "86\n",
      "80\n",
      "54\n",
      "75\n",
      "89\n",
      "91\n",
      "68\n",
      "44\n",
      "39\n",
      "51\n",
      "89\n",
      "82\n",
      "56\n",
      "54\n",
      "85\n",
      "75\n",
      "58\n",
      "73\n",
      "94\n",
      "57\n",
      "76\n",
      "53\n",
      "56\n",
      "66\n",
      "83\n",
      "65\n",
      "56\n",
      "26\n",
      "83\n",
      "81\n",
      "98\n",
      "91\n",
      "42\n",
      "85\n",
      "67\n",
      "38\n",
      "93\n",
      "83\n",
      "94\n",
      "56\n",
      "86\n",
      "53\n",
      "69\n",
      "67\n",
      "76\n",
      "79\n",
      "66\n",
      "60\n",
      "56\n",
      "65\n",
      "58\n",
      "57\n",
      "74\n",
      "68\n",
      "99\n",
      "71\n",
      "31\n",
      "54\n",
      "78\n",
      "53\n",
      "79\n",
      "54\n",
      "84\n",
      "77\n",
      "74\n",
      "64\n",
      "95\n",
      "91\n",
      "93\n",
      "76\n",
      "68\n",
      "74\n",
      "66\n",
      "61\n",
      "66\n",
      "37\n",
      "87\n",
      "67\n",
      "91\n",
      "66\n",
      "62\n",
      "94\n",
      "93\n",
      "83\n",
      "93\n",
      "79\n",
      "60\n",
      "70\n",
      "73\n",
      "54\n",
      "81\n",
      "96\n",
      "68\n",
      "54\n",
      "81\n",
      "58\n",
      "67\n",
      "83\n",
      "84\n",
      "79\n",
      "64\n",
      "52\n",
      "98\n",
      "75\n",
      "66\n",
      "77\n",
      "89\n",
      "85\n",
      "72\n",
      "58\n",
      "91\n",
      "59\n",
      "66\n",
      "33\n",
      "50\n",
      "42\n",
      "91\n",
      "63\n",
      "91\n",
      "73\n",
      "78\n",
      "53\n",
      "64\n",
      "90\n",
      "67\n",
      "66\n",
      "55\n",
      "76\n",
      "79\n",
      "86\n",
      "72\n",
      "95\n",
      "55\n",
      "94\n",
      "62\n",
      "86\n",
      "78\n",
      "97\n",
      "56\n",
      "57\n",
      "63\n",
      "86\n",
      "88\n",
      "65\n",
      "60\n",
      "95\n",
      "67\n",
      "91\n",
      "99\n",
      "71\n",
      "77\n",
      "52\n",
      "59\n",
      "83\n",
      "88\n",
      "86\n",
      "44\n",
      "37\n",
      "38\n",
      "63\n",
      "63\n",
      "75\n",
      "39\n",
      "53\n",
      "56\n",
      "76\n",
      "90\n",
      "49\n",
      "88\n",
      "99\n",
      "66\n",
      "96\n",
      "40\n",
      "76\n",
      "68\n",
      "81\n",
      "56\n",
      "64\n",
      "70\n",
      "39\n",
      "89\n",
      "97\n",
      "55\n",
      "63\n",
      "92\n",
      "49\n",
      "55\n",
      "68\n",
      "51\n",
      "85\n",
      "82\n",
      "69\n",
      "94\n",
      "79\n",
      "83\n",
      "85\n",
      "99\n",
      "74\n",
      "59\n",
      "85\n",
      "73\n",
      "73\n",
      "54\n",
      "47\n",
      "50\n",
      "69\n",
      "73\n",
      "83\n",
      "75\n",
      "90\n",
      "51\n",
      "69\n",
      "57\n",
      "69\n",
      "95\n",
      "66\n",
      "64\n",
      "64\n",
      "79\n",
      "42\n",
      "61\n"
     ]
    }
   ],
   "source": [
    "for i in train_data['tokens']:\n",
    "    if len(i)<100:\n",
    "        print(len(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': Value(dtype='string', id=None),\n",
       " 'label': ClassLabel(names=['neg', 'pos'], id=None),\n",
       " 'tokens': Sequence(feature=Value(dtype='string', id=None), length=-1, id=None)}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label', 'tokens'],\n",
       "    num_rows: 25000\n",
       "})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "256"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data[0]['tokens']) ### mapped from above function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25000"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data['tokens']) ## will load will athe tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'rented',\n",
       " 'i',\n",
       " 'am',\n",
       " 'curious-yellow',\n",
       " 'from',\n",
       " 'my',\n",
       " 'video',\n",
       " 'store',\n",
       " 'because',\n",
       " 'of',\n",
       " 'all',\n",
       " 'the',\n",
       " 'controversy',\n",
       " 'that',\n",
       " 'surrounded',\n",
       " 'it',\n",
       " 'when',\n",
       " 'it',\n",
       " 'was',\n",
       " 'first',\n",
       " 'released',\n",
       " 'in',\n",
       " '1967',\n",
       " '.',\n",
       " 'i',\n",
       " 'also',\n",
       " 'heard',\n",
       " 'that',\n",
       " 'at',\n",
       " 'first',\n",
       " 'it',\n",
       " 'was',\n",
       " 'seized',\n",
       " 'by',\n",
       " 'u',\n",
       " '.',\n",
       " 's',\n",
       " '.',\n",
       " 'customs',\n",
       " 'if',\n",
       " 'it',\n",
       " 'ever',\n",
       " 'tried',\n",
       " 'to',\n",
       " 'enter',\n",
       " 'this',\n",
       " 'country',\n",
       " ',',\n",
       " 'therefore',\n",
       " 'being',\n",
       " 'a',\n",
       " 'fan',\n",
       " 'of',\n",
       " 'films',\n",
       " 'considered',\n",
       " 'controversial',\n",
       " 'i',\n",
       " 'really',\n",
       " 'had',\n",
       " 'to',\n",
       " 'see',\n",
       " 'this',\n",
       " 'for',\n",
       " 'myself',\n",
       " '.',\n",
       " 'the',\n",
       " 'plot',\n",
       " 'is',\n",
       " 'centered',\n",
       " 'around',\n",
       " 'a',\n",
       " 'young',\n",
       " 'swedish',\n",
       " 'drama',\n",
       " 'student',\n",
       " 'named',\n",
       " 'lena',\n",
       " 'who',\n",
       " 'wants',\n",
       " 'to',\n",
       " 'learn',\n",
       " 'everything',\n",
       " 'she',\n",
       " 'can',\n",
       " 'about',\n",
       " 'life',\n",
       " '.',\n",
       " 'in',\n",
       " 'particular',\n",
       " 'she',\n",
       " 'wants',\n",
       " 'to',\n",
       " 'focus',\n",
       " 'her',\n",
       " 'attentions',\n",
       " 'to',\n",
       " 'making',\n",
       " 'some',\n",
       " 'sort',\n",
       " 'of',\n",
       " 'documentary',\n",
       " 'on',\n",
       " 'what',\n",
       " 'the',\n",
       " 'average',\n",
       " 'swede',\n",
       " 'thought',\n",
       " 'about',\n",
       " 'certain',\n",
       " 'political',\n",
       " 'issues',\n",
       " 'such',\n",
       " 'as',\n",
       " 'the',\n",
       " 'vietnam',\n",
       " 'war',\n",
       " 'and',\n",
       " 'race',\n",
       " 'issues',\n",
       " 'in',\n",
       " 'the',\n",
       " 'united',\n",
       " 'states',\n",
       " '.',\n",
       " 'in',\n",
       " 'between',\n",
       " 'asking',\n",
       " 'politicians',\n",
       " 'and',\n",
       " 'ordinary',\n",
       " 'denizens',\n",
       " 'of',\n",
       " 'stockholm',\n",
       " 'about',\n",
       " 'their',\n",
       " 'opinions',\n",
       " 'on',\n",
       " 'politics',\n",
       " ',',\n",
       " 'she',\n",
       " 'has',\n",
       " 'sex',\n",
       " 'with',\n",
       " 'her',\n",
       " 'drama',\n",
       " 'teacher',\n",
       " ',',\n",
       " 'classmates',\n",
       " ',',\n",
       " 'and',\n",
       " 'married',\n",
       " 'men',\n",
       " '.',\n",
       " 'what',\n",
       " 'kills',\n",
       " 'me',\n",
       " 'about',\n",
       " 'i',\n",
       " 'am',\n",
       " 'curious-yellow',\n",
       " 'is',\n",
       " 'that',\n",
       " '40',\n",
       " 'years',\n",
       " 'ago',\n",
       " ',',\n",
       " 'this',\n",
       " 'was',\n",
       " 'considered',\n",
       " 'pornographic',\n",
       " '.',\n",
       " 'really',\n",
       " ',',\n",
       " 'the',\n",
       " 'sex',\n",
       " 'and',\n",
       " 'nudity',\n",
       " 'scenes',\n",
       " 'are',\n",
       " 'few',\n",
       " 'and',\n",
       " 'far',\n",
       " 'between',\n",
       " ',',\n",
       " 'even',\n",
       " 'then',\n",
       " 'it',\n",
       " \"'\",\n",
       " 's',\n",
       " 'not',\n",
       " 'shot',\n",
       " 'like',\n",
       " 'some',\n",
       " 'cheaply',\n",
       " 'made',\n",
       " 'porno',\n",
       " '.',\n",
       " 'while',\n",
       " 'my',\n",
       " 'countrymen',\n",
       " 'mind',\n",
       " 'find',\n",
       " 'it',\n",
       " 'shocking',\n",
       " ',',\n",
       " 'in',\n",
       " 'reality',\n",
       " 'sex',\n",
       " 'and',\n",
       " 'nudity',\n",
       " 'are',\n",
       " 'a',\n",
       " 'major',\n",
       " 'staple',\n",
       " 'in',\n",
       " 'swedish',\n",
       " 'cinema',\n",
       " '.',\n",
       " 'even',\n",
       " 'ingmar',\n",
       " 'bergman',\n",
       " ',',\n",
       " 'arguably',\n",
       " 'their',\n",
       " 'answer',\n",
       " 'to',\n",
       " 'good',\n",
       " 'old',\n",
       " 'boy',\n",
       " 'john',\n",
       " 'ford',\n",
       " ',',\n",
       " 'had',\n",
       " 'sex',\n",
       " 'scenes',\n",
       " 'in',\n",
       " 'his',\n",
       " 'films',\n",
       " '.',\n",
       " 'i',\n",
       " 'do',\n",
       " 'commend',\n",
       " 'the',\n",
       " 'filmmakers',\n",
       " 'for',\n",
       " 'the',\n",
       " 'fact',\n",
       " 'that',\n",
       " 'any',\n",
       " 'sex',\n",
       " 'shown',\n",
       " 'in',\n",
       " 'the',\n",
       " 'film',\n",
       " 'is']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['tokens'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0]['tokens']==train_data['tokens'][0]\n",
    "## however, train_data['tokens'][0] will load all dataset, and select first index. So, prefer to use train_data[0]['tokens'] to be used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'rented',\n",
       " 'i',\n",
       " 'am',\n",
       " 'curious-yellow',\n",
       " 'from',\n",
       " 'my',\n",
       " 'video',\n",
       " 'store',\n",
       " 'because',\n",
       " 'of',\n",
       " 'all',\n",
       " 'the',\n",
       " 'controversy',\n",
       " 'that',\n",
       " 'surrounded',\n",
       " 'it',\n",
       " 'when',\n",
       " 'it',\n",
       " 'was',\n",
       " 'first',\n",
       " 'released',\n",
       " 'in',\n",
       " '1967',\n",
       " '.']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0]['tokens'][:25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "## now we will split 25% of train_data to val_data\n",
    "\n",
    "train_valid_data=train_data.train_test_split(test_size=0.25)\n",
    "train_data=train_valid_data['train']\n",
    "val_data=train_valid_data['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18750"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data) ## total data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a vocabulary\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_freq=1\n",
    "special_tokens=['unk','pad'] ## vocabs which appears less than 5 times or not present will be give 'unk' tokens, and if sample have \n",
    "\n",
    "example_tokens=[['Hi', 'I', 'am', \"Akash\"],\n",
    "                ['Hi', \"how\",\"am\",\"are\"],\n",
    "                ['ez','sir']]\n",
    "\n",
    "example_vocab=torchtext.vocab.build_vocab_from_iterator(\n",
    "    example_tokens,\n",
    "    min_freq=min_freq,\n",
    "    specials=special_tokens\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['unk', 'pad', 'Hi', 'am', 'Akash', 'I', 'are', 'ez', 'how', 'sir']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## see the how vocab is used\n",
    "example_vocab.get_itos() ## first vocabs is filled with special tokens, later the most repeated tokens first. If same freq is same then according to alphabetical value "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unk idx : 0\n",
      "Akash:  4\n"
     ]
    }
   ],
   "source": [
    "## Check the IDX value \n",
    "print('unk idx :',example_vocab['unk'])\n",
    "print('Akash: ',example_vocab['Akash'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "## checking if the word is in vocabulary\n",
    "print(\"Akash\" in example_vocab)\n",
    "print(\"akash\" in example_vocab)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Can't access the tokens in vocabs \n"
     ]
    }
   ],
   "source": [
    "## What if the tokens is not in dictionary\n",
    "try:\n",
    "    example_vocab['akash']\n",
    "except:\n",
    "    print(\"Can't access the tokens in vocabs \") \n",
    "\n",
    "## so in order to return 'unk' tokens or 0 value for tokens not in dictionary we have to do thus\n",
    "unk_idx=example_vocab['unk']\n",
    "example_vocab.set_default_index(unk_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_vocab['akash'] ## return 0 for unknown tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 0]\n"
     ]
    }
   ],
   "source": [
    "##list of tokens to indices\n",
    "example_tokens_to_indices=example_vocab.lookup_indices([\"Hi\", \"Nepal\"])\n",
    "print(example_tokens_to_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating Vocabulary on train_data\n",
    "\n",
    "Note: We only create vocabs on train_data; Not on test data so that information is not leaked. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_freq=5\n",
    "special_tokens=['unk','pad'] ## vocabs which appears less than 5 times or not present will be give 'unk' tokens, and if sample have \n",
    "\n",
    "vocab=torchtext.vocab.build_vocab_from_iterator(\n",
    "    train_data['tokens'],\n",
    "    min_freq=min_freq,\n",
    "    specials=special_tokens\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample tokenized example:  ['hello', ',', 'i', 'am', 'from', 'nepal', '!']\n"
     ]
    }
   ],
   "source": [
    "print('sample tokenized example: ',sample_tokenized_text)\n",
    "# print('ids from tokens: ',vocab(sample_tokenized_text)) ## converted to int value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab.set_default_index(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4927"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab['hello']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4927, 4, 12, 220, 45, 18618, 36]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab.lookup_indices(sample_tokenized_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[900,\n",
       " 446,\n",
       " 10,\n",
       " 34,\n",
       " 7,\n",
       " 2,\n",
       " 131,\n",
       " 7,\n",
       " 2,\n",
       " 1503,\n",
       " 113,\n",
       " 167,\n",
       " 2,\n",
       " 2470,\n",
       " 3,\n",
       " 11,\n",
       " 17,\n",
       " 637,\n",
       " 241,\n",
       " 300,\n",
       " 104,\n",
       " 2,\n",
       " 10262,\n",
       " 318,\n",
       " 7]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab.lookup_indices(train_data[0]['tokens'])[:25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|| 18750/18750 [00:07<00:00, 2508.36 examples/s]\n",
      "Map: 100%|| 6250/6250 [00:02<00:00, 2562.10 examples/s]\n",
      "Map: 100%|| 25000/25000 [00:08<00:00, 2986.93 examples/s]\n"
     ]
    }
   ],
   "source": [
    "## we will add the indices features to train_data\n",
    "\n",
    "def  numericialize_tokens(example,vocab):\n",
    "    ids=vocab.lookup_indices(example['tokens'])\n",
    "    return {'ids':ids}\n",
    "\n",
    "train_data=train_data.map(numericialize_tokens,\n",
    "                          fn_kwargs={'vocab':vocab})\n",
    "\n",
    "\n",
    "val_data=val_data.map(numericialize_tokens,\n",
    "                          fn_kwargs={'vocab':vocab})\n",
    "\n",
    "test_data=test_data.map(numericialize_tokens,\n",
    "                        fn_kwargs={'vocab':vocab})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapped train_data.features:  {'text': Value(dtype='string', id=None), 'label': ClassLabel(names=['neg', 'pos'], id=None), 'tokens': Sequence(feature=Value(dtype='string', id=None), length=-1, id=None), 'ids': Sequence(feature=Value(dtype='int64', id=None), length=-1, id=None)}\n"
     ]
    }
   ],
   "source": [
    "print('mapped train_data.features: ',train_data.features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1233,\n",
       " 172,\n",
       " 13340,\n",
       " 15975,\n",
       " 11214,\n",
       " 9,\n",
       " 16,\n",
       " 427,\n",
       " 95,\n",
       " 1018,\n",
       " 3671,\n",
       " 10,\n",
       " 14,\n",
       " 197,\n",
       " 4,\n",
       " 5,\n",
       " 1592,\n",
       " 1143,\n",
       " 65,\n",
       " 0,\n",
       " 3,\n",
       " 1592,\n",
       " 1143,\n",
       " 65,\n",
       " 400]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0]['ids'][:25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "## creatomg tp pytoprch\n",
    "train_data=train_data.with_format(type='torch',columns=['ids','label']) ## convert \"ids\" and \"label\" features to torch format ; Not  other\n",
    "test_data=test_data.with_format(type='torch',columns=['ids','label'])\n",
    "val_data=val_data.with_format(type='torch',columns=['ids','label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_data[0]['ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_collate_fnc(pad_index):\n",
    "    \n",
    "    def collate_fnc(batch):\n",
    "        batch_ids=[i['ids'] for i in batch] ## You can try [i['ids'] for i train_data] train_data_len==batch\n",
    "        batch_ids=torch.nn.utils.rnn.pad_sequence(batch_ids,padding_value=pad_index,batch_first=True)\n",
    "        batch_label=[i['label'] for i in batch]\n",
    "        batch_label=torch.stack(batch_label)\n",
    "        batch={'ids':batch_ids,'label':batch_label}\n",
    "        return batch\n",
    "    return collate_fnc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "## define Dataloader\n",
    "\n",
    "def get_data_loader(dataset,batch_size,pad_index,shuffle=False):\n",
    "    collate_fnc=get_collate_fnc(pad_index=pad_index)\n",
    "    data_loader=DataLoader(dataset,\n",
    "                           batch_size=batch_size,\n",
    "                           collate_fn=collate_fnc,\n",
    "                           shuffle=shuffle)\n",
    "    return data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "## set shuffle ==True only for train_dataloader\n",
    "batch_size=512\n",
    "pad_idx=0\n",
    "train_data_loader=get_data_loader(train_data,batch_size=batch_size,pad_index=pad_idx,shuffle=True)\n",
    "test_data_loader=get_data_loader(test_data,batch_size=batch_size,pad_index=pad_idx)\n",
    "val_data_loader=get_data_loader(val_data,batch_size=batch_size,pad_index=pad_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512, 256])\n",
      "torch.Size([512, 256])\n",
      "torch.Size([512, 256])\n",
      "torch.Size([512, 256])\n",
      "torch.Size([512, 256])\n",
      "torch.Size([512, 256])\n",
      "torch.Size([512, 256])\n",
      "torch.Size([512, 256])\n",
      "torch.Size([512, 256])\n",
      "torch.Size([512, 256])\n"
     ]
    }
   ],
   "source": [
    "for num,batch in enumerate(train_data_loader):\n",
    "    if num==10:\n",
    "        break\n",
    "\n",
    "    print(batch['ids'].shape)\n",
    "\n",
    "train_data_loader=get_data_loader(train_data,batch_size=batch_size,pad_index=pad_idx,shuffle=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([512, 256])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch['ids'].shape ## batch_size,max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "### defining a Neural Bag of Words\n",
    "class NBoW(nn.Module):\n",
    "\n",
    "    def __init__(self,vocab_size,embedding_dim,output_dim):\n",
    "        super(NBoW,self).__init__()\n",
    "        self.embedding=nn.Embedding(num_embeddings=vocab_size,embedding_dim=embedding_dim) ## return batch_size,num_tokens,emdbedding_dim\n",
    "        self.fc=nn.Linear(in_features=embedding_dim,out_features=output_dim)\n",
    "\n",
    "    def forward(self,x):\n",
    "        embedding_output=self.embedding(x) ## return batch_size,num_tokens,emdbedding_dim\n",
    "        polled_output=embedding_output.mean(dim=1) ## returns batch_size,embedding_dim\n",
    "        prediction=self.fc(polled_output)\n",
    "        return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "## defining the training parameters \n",
    "\n",
    "vocab_size=len(vocab)\n",
    "embedding_dim=300\n",
    "output_dim=len(train_data.unique('label'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ids.shape : torch.Size([512, 256])\n",
      "test_output.shape:  torch.Size([512, 2])\n",
      "real_label.shape\n"
     ]
    }
   ],
   "source": [
    "##testing the model on defined model\n",
    "\n",
    "nbow=NBoW(vocab_size,embedding_dim,output_dim).to(device=device)\n",
    "ids=batch['ids'].to(device=device)\n",
    "print('ids.shape :',ids.shape)\n",
    "\n",
    "test_output=nbow(ids)\n",
    "print('test_output.shape: ',test_output.shape)\n",
    "print('real_label.shape')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=torch.tensor([1,2,3,4,5],dtype=torch.float32)\n",
    "b=torch.tensor([1,2,3,8,9],dtype=torch.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.5000)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.eq(b).sum()/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "## defining accuracy\n",
    "\n",
    "def get_accuracy(prediction,label):\n",
    "    batch_size,_=prediction.shape\n",
    "    prediction_classes=prediction.argmax(dim=1)\n",
    "    corrected_prediction=prediction_classes.eq(label).sum()\n",
    "    accuracy=corrected_prediction/batch_size\n",
    "    return accuracy ## return tnesor as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(data_loader, model, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    epoch_losses = []\n",
    "    epoch_accs = []\n",
    "    for batch in tqdm.tqdm(data_loader, desc=\"training...\"):\n",
    "        ids = batch[\"ids\"].to(device)\n",
    "        label = batch[\"label\"].to(device)\n",
    "        prediction = model(ids)\n",
    "        loss = criterion(prediction, label)\n",
    "        accuracy = get_accuracy(prediction, label)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_losses.append(loss.item())\n",
    "        epoch_accs.append(accuracy.item())\n",
    "    return np.mean(epoch_losses), np.mean(epoch_accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(data_loader, model, criterion, device):\n",
    "    model.eval()\n",
    "    epoch_losses = []\n",
    "    epoch_accs = []\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm.tqdm(data_loader, desc=\"evaluating...\"):\n",
    "            ids = batch[\"ids\"].to(device)\n",
    "            label = batch[\"label\"].to(device)\n",
    "            prediction = model(ids)\n",
    "            loss = criterion(prediction, label)\n",
    "            accuracy = get_accuracy(prediction, label)\n",
    "            epoch_losses.append(loss.item())\n",
    "            epoch_accs.append(accuracy.item())\n",
    "    return np.mean(epoch_losses), np.mean(epoch_accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "##defining criterion\n",
    "criterion=nn.CrossEntropyLoss().to(device=device)\n",
    "optimizer=torch.optim.Adam(nbow.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training...: 100%|| 37/37 [00:01<00:00, 33.94it/s]\n",
      "evaluating...: 100%|| 13/13 [00:00<00:00, 48.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Num:  0\n",
      "Train Loss: 0.688   | Train Acc: 0.561\n",
      "Val Loss: 0.676   | Val Acc: 0.636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training...: 100%|| 37/37 [00:00<00:00, 38.67it/s]\n",
      "evaluating...: 100%|| 13/13 [00:00<00:00, 44.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Num:  1\n",
      "Train Loss: 0.663   | Train Acc: 0.678\n",
      "Val Loss: 0.650   | Val Acc: 0.695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training...: 100%|| 37/37 [00:00<00:00, 38.26it/s]\n",
      "evaluating...: 100%|| 13/13 [00:00<00:00, 50.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Num:  2\n",
      "Train Loss: 0.633   | Train Acc: 0.706\n",
      "Val Loss: 0.618   | Val Acc: 0.726\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training...: 100%|| 37/37 [00:01<00:00, 34.07it/s]\n",
      "evaluating...: 100%|| 13/13 [00:00<00:00, 49.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Num:  3\n",
      "Train Loss: 0.594   | Train Acc: 0.740\n",
      "Val Loss: 0.581   | Val Acc: 0.740\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training...: 100%|| 37/37 [00:00<00:00, 37.94it/s]\n",
      "evaluating...: 100%|| 13/13 [00:00<00:00, 47.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Num:  4\n",
      "Train Loss: 0.551   | Train Acc: 0.770\n",
      "Val Loss: 0.542   | Val Acc: 0.774\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training...: 100%|| 37/37 [00:00<00:00, 38.97it/s]\n",
      "evaluating...: 100%|| 13/13 [00:00<00:00, 46.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Num:  5\n",
      "Train Loss: 0.505   | Train Acc: 0.800\n",
      "Val Loss: 0.504   | Val Acc: 0.791\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training...: 100%|| 37/37 [00:00<00:00, 37.94it/s]\n",
      "evaluating...: 100%|| 13/13 [00:00<00:00, 46.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Num:  6\n",
      "Train Loss: 0.462   | Train Acc: 0.823\n",
      "Val Loss: 0.469   | Val Acc: 0.812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training...: 100%|| 37/37 [00:01<00:00, 35.78it/s]\n",
      "evaluating...: 100%|| 13/13 [00:00<00:00, 47.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Num:  7\n",
      "Train Loss: 0.422   | Train Acc: 0.849\n",
      "Val Loss: 0.440   | Val Acc: 0.825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training...: 100%|| 37/37 [00:01<00:00, 34.34it/s]\n",
      "evaluating...: 100%|| 13/13 [00:00<00:00, 43.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Num:  8\n",
      "Train Loss: 0.387   | Train Acc: 0.865\n",
      "Val Loss: 0.416   | Val Acc: 0.834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training...: 100%|| 37/37 [00:01<00:00, 32.82it/s]\n",
      "evaluating...: 100%|| 13/13 [00:00<00:00, 45.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Num:  9\n",
      "Train Loss: 0.358   | Train Acc: 0.876\n",
      "Val Loss: 0.397   | Val Acc: 0.839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training...: 100%|| 37/37 [00:01<00:00, 31.40it/s]\n",
      "evaluating...: 100%|| 13/13 [00:00<00:00, 40.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Num:  10\n",
      "Train Loss: 0.332   | Train Acc: 0.888\n",
      "Val Loss: 0.380   | Val Acc: 0.846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training...: 100%|| 37/37 [00:01<00:00, 27.77it/s]\n",
      "evaluating...: 100%|| 13/13 [00:00<00:00, 42.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Num:  11\n",
      "Train Loss: 0.310   | Train Acc: 0.896\n",
      "Val Loss: 0.366   | Val Acc: 0.850\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training...: 100%|| 37/37 [00:01<00:00, 31.21it/s]\n",
      "evaluating...: 100%|| 13/13 [00:00<00:00, 44.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Num:  12\n",
      "Train Loss: 0.291   | Train Acc: 0.903\n",
      "Val Loss: 0.355   | Val Acc: 0.851\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training...: 100%|| 37/37 [00:01<00:00, 30.99it/s]\n",
      "evaluating...: 100%|| 13/13 [00:00<00:00, 41.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Num:  13\n",
      "Train Loss: 0.274   | Train Acc: 0.909\n",
      "Val Loss: 0.346   | Val Acc: 0.856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training...: 100%|| 37/37 [00:01<00:00, 30.01it/s]\n",
      "evaluating...: 100%|| 13/13 [00:00<00:00, 43.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Num:  14\n",
      "Train Loss: 0.259   | Train Acc: 0.916\n",
      "Val Loss: 0.338   | Val Acc: 0.857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training...: 100%|| 37/37 [00:01<00:00, 30.22it/s]\n",
      "evaluating...: 100%|| 13/13 [00:00<00:00, 42.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Num:  15\n",
      "Train Loss: 0.244   | Train Acc: 0.922\n",
      "Val Loss: 0.332   | Val Acc: 0.861\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training...: 100%|| 37/37 [00:01<00:00, 30.25it/s]\n",
      "evaluating...: 100%|| 13/13 [00:00<00:00, 42.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Num:  16\n",
      "Train Loss: 0.234   | Train Acc: 0.925\n",
      "Val Loss: 0.328   | Val Acc: 0.862\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training...: 100%|| 37/37 [00:01<00:00, 30.24it/s]\n",
      "evaluating...: 100%|| 13/13 [00:00<00:00, 44.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Num:  17\n",
      "Train Loss: 0.221   | Train Acc: 0.929\n",
      "Val Loss: 0.322   | Val Acc: 0.864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training...: 100%|| 37/37 [00:01<00:00, 30.88it/s]\n",
      "evaluating...: 100%|| 13/13 [00:00<00:00, 41.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Num:  18\n",
      "Train Loss: 0.210   | Train Acc: 0.936\n",
      "Val Loss: 0.319   | Val Acc: 0.867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training...: 100%|| 37/37 [00:01<00:00, 28.30it/s]\n",
      "evaluating...: 100%|| 13/13 [00:00<00:00, 43.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Num:  19\n",
      "Train Loss: 0.201   | Train Acc: 0.938\n",
      "Val Loss: 0.316   | Val Acc: 0.867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training...: 100%|| 37/37 [00:01<00:00, 31.18it/s]\n",
      "evaluating...: 100%|| 13/13 [00:00<00:00, 43.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Num:  20\n",
      "Train Loss: 0.191   | Train Acc: 0.942\n",
      "Val Loss: 0.313   | Val Acc: 0.868\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training...: 100%|| 37/37 [00:01<00:00, 30.85it/s]\n",
      "evaluating...: 100%|| 13/13 [00:00<00:00, 43.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Num:  21\n",
      "Train Loss: 0.183   | Train Acc: 0.946\n",
      "Val Loss: 0.310   | Val Acc: 0.871\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training...: 100%|| 37/37 [00:01<00:00, 30.92it/s]\n",
      "evaluating...: 100%|| 13/13 [00:00<00:00, 43.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Num:  22\n",
      "Train Loss: 0.175   | Train Acc: 0.947\n",
      "Val Loss: 0.310   | Val Acc: 0.871\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training...: 100%|| 37/37 [00:01<00:00, 30.96it/s]\n",
      "evaluating...: 100%|| 13/13 [00:00<00:00, 42.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Num:  23\n",
      "Train Loss: 0.168   | Train Acc: 0.950\n",
      "Val Loss: 0.307   | Val Acc: 0.874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training...: 100%|| 37/37 [00:01<00:00, 29.94it/s]\n",
      "evaluating...: 100%|| 13/13 [00:00<00:00, 42.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Num:  24\n",
      "Train Loss: 0.160   | Train Acc: 0.953\n",
      "Val Loss: 0.306   | Val Acc: 0.873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "evaluating...: 100%|| 13/13 [00:00<00:00, 41.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Val Loss: 0.504   | Best Val Acc: 0.791\n"
     ]
    }
   ],
   "source": [
    "save_dire=\"../saved_model/nbow.pt\"\n",
    "n_epochs=25\n",
    "best_valid_loss=float(\"inf\")\n",
    "\n",
    "metrics=collections.defaultdict(list)\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    train_loss,train_acc=train(train_data_loader,device=device,\n",
    "                                  model=nbow,criterion=criterion,\n",
    "                                  optimizer=optimizer)\n",
    "    \n",
    "    val_loss,val_acc=evaluate(val_data_loader,device=device,\n",
    "                                  model=nbow,criterion=criterion\n",
    "                        )\n",
    "    \n",
    "    metrics['train_loss'].append(train_loss)\n",
    "    metrics['train_acc'].append(train_acc)\n",
    "    metrics['val_loss'].append(val_loss)\n",
    "    metrics['val_acc'].append(val_acc)\n",
    "    if val_loss<train_loss:\n",
    "       \n",
    "        best_valid_loss=val_loss\n",
    "        \n",
    "        torch.save(nbow.state_dict(),save_dire)\n",
    "\n",
    "    print(\"Epoch Num: \", epoch)\n",
    "    print('Train Loss: {:.3f}   | Train Acc: {:.3f}'.format(train_loss,train_acc))\n",
    "    print('Val Loss: {:.3f}   | Val Acc: {:.3f}'.format(val_loss,val_acc))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# best Validation loss\n",
    "\n",
    "nbow.load_state_dict(torch.load(save_dire))\n",
    "best_val_loss,best_val_acc=evaluate(val_data_loader,device=device,\n",
    "                                  model=nbow,criterion=criterion\n",
    "                                )\n",
    "\n",
    "print('Best Val Loss: {:.3f}   | Best Val Acc: {:.3f}'.format(best_val_loss,best_val_acc))\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure(figsize=(10, 6))\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "ax.plot(metrics[\"train_losses\"], label=\"train loss\")\n",
    "ax.plot(metrics[\"valid_losses\"], label=\"valid loss\")\n",
    "ax.set_xlabel(\"epoch\")\n",
    "ax.set_ylabel(\"loss\")\n",
    "ax.set_xticks(range(n_epochs))\n",
    "ax.legend()\n",
    "ax.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vision",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
